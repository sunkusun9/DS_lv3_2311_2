{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75850728",
   "metadata": {},
   "source": [
    "# 시험장 환경 정보\n",
    "\n",
    "Python: 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
    "\n",
    "|모듈|버젼|\n",
    "|----|----|\n",
    "|pandas|0.25.1|\n",
    "|numpy|1.18.5|\n",
    "|sklearn|0.21.3|\n",
    "|scipy|1.5.2|\n",
    "|mlxtend|0.15.0.0|\n",
    "|statsmodels|0.11.1|\n",
    "|xgboost|0.8|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b1901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 0.25.1\n",
      "numpy 1.18.5\n",
      "sklearn 0.21.3\n",
      "scipy 1.5.2\n",
      "mlxtend 0.15.0.0\n",
      "statsmodels 0.11.1\n",
      "xgboost 0.80\n"
     ]
    }
   ],
   "source": [
    "# 실행 환경 확인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "import mlxtend\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels, xgb]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a5207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 모듈 설정\n",
    "# 참고용 차트를 출력하기 위함\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "mpl.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719eb2d",
   "metadata": {},
   "source": [
    "# 문제 개요\n",
    "\n",
    "다음은 폴더블 폰의 힌지에 들어가는 스프링 내구력을 테스트한 실험 결과이다. \n",
    "\n",
    "스프링 측정값과 스프링에 가한 부하 정보와 함께, 테스트 통과/실패 (failure) 결과가 기재되어 있다. \n",
    "\n",
    "개발부서는 테스트 비용을 줄이기 위해 failure 여부를 맞추는 모델을 만들고자 한다.\n",
    "\n",
    "변수명은 보안을 위해 measurement_0과 같이 익명화되었다.\n",
    "\n",
    "데이터 구성\n",
    "\n",
    "학습데이터: train_prob.csv, 21,458 rows, 25 columns\n",
    "\n",
    "테스트데이터: test_prob.csv, 5,112 rows, 24 columns, \n",
    "\n",
    "테스트정답셋: test_prob_ans.csv, 5,112 rows, 1 columns\n",
    "\n",
    "\n",
    "컬럼명\t설명\t타입\n",
    "\n",
    "|변수명|설명|타입|\n",
    "|--|--------------|------|\n",
    "|id|실험 고유 번호|정수형|\n",
    "|product_code|스프링 코드|범주형|\n",
    "|loading|스프링에 가한 부하|실수형|\n",
    "|attribute_0|구성 소재1|범주형|\n",
    "|attribute_1|구성 소재2|범주형|\n",
    "|attribute_2|구성 소재3|정수형|\n",
    "|attribute_3|구성 소재4|정수형|\n",
    "|measurement_0 ~ 17|측정값 0~17|실수형|\n",
    "|failure|성공여부|이진형(0, 1)|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebc269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b80d1407",
   "metadata": {},
   "source": [
    "# 전처리(Preprocessing)\n",
    "\n",
    "train_prob.csv를 불러 온다. 이를 basetable이리고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ca3fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_code</th>\n",
       "      <th>loading</th>\n",
       "      <th>attribute_0</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>...</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80.10</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>18.040</td>\n",
       "      <td>...</td>\n",
       "      <td>10.672</td>\n",
       "      <td>15.859</td>\n",
       "      <td>17.594</td>\n",
       "      <td>15.193</td>\n",
       "      <td>15.029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.034</td>\n",
       "      <td>14.684</td>\n",
       "      <td>764.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>84.89</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18.213</td>\n",
       "      <td>...</td>\n",
       "      <td>12.448</td>\n",
       "      <td>17.947</td>\n",
       "      <td>17.915</td>\n",
       "      <td>11.755</td>\n",
       "      <td>14.732</td>\n",
       "      <td>15.425</td>\n",
       "      <td>14.395</td>\n",
       "      <td>15.631</td>\n",
       "      <td>682.057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>82.43</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>18.057</td>\n",
       "      <td>...</td>\n",
       "      <td>12.715</td>\n",
       "      <td>15.607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.798</td>\n",
       "      <td>16.711</td>\n",
       "      <td>18.631</td>\n",
       "      <td>14.094</td>\n",
       "      <td>17.946</td>\n",
       "      <td>663.376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>101.07</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>17.295</td>\n",
       "      <td>...</td>\n",
       "      <td>12.471</td>\n",
       "      <td>16.346</td>\n",
       "      <td>18.377</td>\n",
       "      <td>10.020</td>\n",
       "      <td>15.250</td>\n",
       "      <td>15.562</td>\n",
       "      <td>16.154</td>\n",
       "      <td>17.172</td>\n",
       "      <td>826.282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>188.06</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>19.346</td>\n",
       "      <td>...</td>\n",
       "      <td>10.337</td>\n",
       "      <td>17.082</td>\n",
       "      <td>19.932</td>\n",
       "      <td>12.428</td>\n",
       "      <td>16.182</td>\n",
       "      <td>12.760</td>\n",
       "      <td>13.153</td>\n",
       "      <td>16.412</td>\n",
       "      <td>579.885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_code  loading attribute_0 attribute_1  attribute_2  attribute_3  \\\n",
       "id                                                                           \n",
       "0             A    80.10  material_7  material_8            9            5   \n",
       "1             A    84.89  material_7  material_8            9            5   \n",
       "2             A    82.43  material_7  material_8            9            5   \n",
       "3             A   101.07  material_7  material_8            9            5   \n",
       "4             A   188.06  material_7  material_8            9            5   \n",
       "\n",
       "    measurement_0  measurement_1  measurement_2  measurement_3  ...  \\\n",
       "id                                                              ...   \n",
       "0               7              8              4         18.040  ...   \n",
       "1              14              3              3         18.213  ...   \n",
       "2              12              1              5         18.057  ...   \n",
       "3              13              2              6         17.295  ...   \n",
       "4               9              2              8         19.346  ...   \n",
       "\n",
       "    measurement_9  measurement_10  measurement_11  measurement_12  \\\n",
       "id                                                                  \n",
       "0          10.672          15.859          17.594          15.193   \n",
       "1          12.448          17.947          17.915          11.755   \n",
       "2          12.715          15.607             NaN          13.798   \n",
       "3          12.471          16.346          18.377          10.020   \n",
       "4          10.337          17.082          19.932          12.428   \n",
       "\n",
       "    measurement_13  measurement_14  measurement_15  measurement_16  \\\n",
       "id                                                                   \n",
       "0           15.029             NaN          13.034          14.684   \n",
       "1           14.732          15.425          14.395          15.631   \n",
       "2           16.711          18.631          14.094          17.946   \n",
       "3           15.250          15.562          16.154          17.172   \n",
       "4           16.182          12.760          13.153          16.412   \n",
       "\n",
       "    measurement_17  failure  \n",
       "id                           \n",
       "0          764.100        0  \n",
       "1          682.057        0  \n",
       "2          663.376        0  \n",
       "3          826.282        0  \n",
       "4          579.885        0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21458 entries, 0 to 26569\n",
      "Data columns (total 25 columns):\n",
      "product_code      21458 non-null object\n",
      "loading           21257 non-null float64\n",
      "attribute_0       21458 non-null object\n",
      "attribute_1       21458 non-null object\n",
      "attribute_2       21458 non-null int64\n",
      "attribute_3       21458 non-null int64\n",
      "measurement_0     21458 non-null int64\n",
      "measurement_1     21458 non-null int64\n",
      "measurement_2     21458 non-null int64\n",
      "measurement_3     21146 non-null float64\n",
      "measurement_4     21016 non-null float64\n",
      "measurement_5     20893 non-null float64\n",
      "measurement_6     20818 non-null float64\n",
      "measurement_7     20692 non-null float64\n",
      "measurement_8     20605 non-null float64\n",
      "measurement_9     20469 non-null float64\n",
      "measurement_10    20399 non-null float64\n",
      "measurement_11    20278 non-null float64\n",
      "measurement_12    20171 non-null float64\n",
      "measurement_13    20063 non-null float64\n",
      "measurement_14    19976 non-null float64\n",
      "measurement_15    19855 non-null float64\n",
      "measurement_16    19750 non-null float64\n",
      "measurement_17    19640 non-null float64\n",
      "failure           21458 non-null int64\n",
      "dtypes: float64(16), int64(6), object(3)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# 샘플별로 유일성을 지닌 식별할 수 있는 시퀀스 번호 id는 인덱스에 위치시킵니다(index_col)\n",
    "df_basetable = pd.read_csv('train_prob.csv', index_col='id')\n",
    "display(df_basetable.head())\n",
    "df_basetable.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f35976",
   "metadata": {},
   "source": [
    "# 단계 1\n",
    "\n",
    "basetable에 measurement_3 ~17 각각의 행이 결측인지 나타내는 파생 변수를 만든다. \n",
    "\n",
    "파생 변수는 이진 형식이고, False는 미결측 True는 결측을 의미한다. \n",
    "\n",
    "파생 변수의 이름은 measurement 번호에 따라 isna_3 ~ 17로 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d8bd808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basetable[['isna_{}'.format(i) for i in range(3, 18)]] = \\\n",
    "    df_basetable[['measurement_{}'.format(i) for i in range(3, 18)]].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9189330a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isna_3      312\n",
       "isna_4      442\n",
       "isna_5      565\n",
       "isna_6      640\n",
       "isna_7      766\n",
       "isna_8      853\n",
       "isna_9      989\n",
       "isna_10    1059\n",
       "isna_11    1180\n",
       "isna_12    1287\n",
       "isna_13    1395\n",
       "isna_14    1482\n",
       "isna_15    1603\n",
       "isna_16    1708\n",
       "isna_17    1818\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치의 수를 확인해 봅니다.\n",
    "df_basetable[['isna_{}'.format(i) for i in range(3, 18)]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173737d",
   "metadata": {},
   "source": [
    "## 단계 2\n",
    "\n",
    "이 과제를 맡은 데이터분석가 지희는 measurement_3~17의 결측치 처리 방안을 고민하던 중, \n",
    "\n",
    "개발부서에서 measurement_17은 product_code별로 failure를 예측하기 위해 \n",
    "\n",
    "measurement_3 ~ measurement_9을 다음과 같이 선형 조합하여 생성한 값이라는 정보를 받았다. \n",
    "\n",
    "$measurement_{17}=\\beta_{3}measurement_{3}+\\beta_{4}measurement_{4}+...+\\beta_{9}measurement_{9}$\n",
    "\n",
    "이는 즉, \n",
    "\n",
    "$measurement_{3}=\\beta'_{4}measurement_{4}+\\beta'_{5}measurement_{5}+...+\\beta_{9}measurement_{9} + \\beta'_{17}measurement_{17}$\n",
    "\n",
    "...\n",
    "\n",
    "$measurement_{9}=\\beta''_{3}measurement_{3}+\\beta''_{4}measurement_{4}+...+\\beta_{8}measurement_{8}+\\beta''_{17}measurement_{17}$\n",
    "\n",
    "와 같이 measurement_3 ~ measurement_9의 각 변수들도 나머지 변수들과 선형 관계를 지닌다. \n",
    "\n",
    "이 점을 이용하여 대상 변수를 번갈아 가면서 예측 모델을 만들어 최대한 원래 값에 가깝게 복원할 수 있다. \n",
    "\n",
    "이러한 반복적인 결측치 복원 방법을 사내 데이터분석 연구소에 문의 했더니 다음과 같은 가이드를 주었다. \n",
    "\n",
    "> sklearn 모듈에 아직은 실험 단계이지만, 비슷한 경우에 문제 없이 사용했던 사례가 있어 의견을 드립니다. \n",
    "\n",
    "> from sklearn.experimental import enable_iterative_imputer 구문을 사용하여 실험 단계인 모듈을 활성화하고, \n",
    "\n",
    "> sklearn.impute.IterativeImputer를 사용한다면 원하는 결과를 얻을 수 있습니다.\n",
    "\n",
    "가이드의 내용을 참조하여 basetable의 measurement_3~9와 measurement_17 결측치를 복원하라.\n",
    "\n",
    "\n",
    "입력 변수] measurement_3 ~ 9, measurement_17 (입력 변수 순서에 유의)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.experimental.enable_iterative_imputer\n",
    "\n",
    "sklearn.impute.IterativeImputer, random_state=123\n",
    "\n",
    "sklearn.linear_model.LinearRegression\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a94de17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 1: 수준 별로 모델을 만들어 Series에 담아 두고, 수준 별로 적용합니다.\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 수준 별로 모델의 인스턴스를 만들어 주기 위한 함수 입니다.\n",
    "def create_imp():\n",
    "    return IterativeImputer(\n",
    "        estimator=LinearRegression(),\n",
    "        random_state=123\n",
    "    )\n",
    "X_imp = ['measurement_{}'.format(i) for i in range(3, 10)] + ['measurement_17']\n",
    "# 수준별로 결측 보간 모델을 만들고 학습합니다.\n",
    "s_imp = df_basetable.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: create_imp().fit(x[X_imp])\n",
    ")\n",
    "# 모델을 적용하여 결측이 처리된 데이터프레임을 만듭니다.\n",
    "# apply에서 transform에서 numpy array를 넘겨 주므로, \n",
    "# DataFrame을 만들어 반환시켜주면,\n",
    "# apply에서 DataFrame으로 재구성하여 넘겨줍니다.\n",
    "df_basetable[X_imp] = df_basetable.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: pd.DataFrame(s_imp.loc[x.name].transform(x[X_imp]), index=x.index, columns=X_imp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6e04654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 2: 수준 별로 모델을 만듦과 동시에 변환을 시킵니다.\n",
    "\n",
    "# 이 때는 따로 모델을 지니고 있지 않기 때문에, 공통으로 사용할 모델 인스턴스 하나만 생성합니다.\n",
    "imp = IterativeImputer(\n",
    "    estimator=LinearRegression(),\n",
    "    random_state=123\n",
    ")\n",
    "X_imp = ['measurement_{}'.format(i) for i in range(3, 10)] + ['measurement_17']\n",
    "df_basetable[X_imp] = df_basetable.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: pd.DataFrame(imp.fit_transform(x[X_imp]), index=x.index, columns=X_imp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21c99c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 3: 반복문을 이용합니다.\n",
    "\n",
    "X_imp = ['measurement_{}'.format(i) for i in range(3, 10)] + ['measurement_17']\n",
    "imp = IterativeImputer(\n",
    "    estimator=LinearRegression(),\n",
    "    random_state=123\n",
    ")\n",
    "for i in df_basetable['product_code'].unique():\n",
    "    s_bidx = df_basetable['product_code'] == i\n",
    "    # 값을 대입할 때, 대입에 대상이 되는 데이터프레임을\n",
    "    # df_basetable.loc[s_bidx][X_imp] 이런식으로 filtering -> 컬럼선택 2단계로 할 경우 reference 경고를 받게 됩니다.\n",
    "    # df_basetable.loc[s_bidx, X_imp] filtering과 columns 선택을 하여 중간에 reference DataFrame 없이 처리하도록 합니다.\n",
    "    df_basetable.loc[s_bidx, X_imp] = imp.fit_transform(df_basetable.loc[s_bidx, X_imp])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95edba8",
   "metadata": {},
   "source": [
    "## 단계 3\n",
    "\n",
    "measurement_10~16까지의 결측치는 모두 product_code별 평균으로 대치한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bea1389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply를 사용해봅니다. \n",
    "# apply 사용후 groupby에 의해 구분된 수준이 불필요(1:1 변환작업이라는 점에서)하게 index에 붙을 수가 있습니다.\n",
    "# 이 때는 DataFrame에 index를 지정하여 반환시키면 없앨 수 있습니다.\n",
    "X_mean = ['measurement_{}'.format(i) for i in range(10, 17)]\n",
    "df_basetable[X_mean] = \\\n",
    "    df_basetable.groupby('product_code')[X_mean].apply(lambda x: pd.DataFrame(x.fillna(x.mean()), index=x.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9c2f5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15.859</td>\n",
       "      <td>17.594000</td>\n",
       "      <td>15.193</td>\n",
       "      <td>15.029</td>\n",
       "      <td>16.110886</td>\n",
       "      <td>13.034</td>\n",
       "      <td>14.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17.947</td>\n",
       "      <td>17.915000</td>\n",
       "      <td>11.755</td>\n",
       "      <td>14.732</td>\n",
       "      <td>15.425000</td>\n",
       "      <td>14.395</td>\n",
       "      <td>15.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15.607</td>\n",
       "      <td>19.439558</td>\n",
       "      <td>13.798</td>\n",
       "      <td>16.711</td>\n",
       "      <td>18.631000</td>\n",
       "      <td>14.094</td>\n",
       "      <td>17.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>16.346</td>\n",
       "      <td>18.377000</td>\n",
       "      <td>10.020</td>\n",
       "      <td>15.250</td>\n",
       "      <td>15.562000</td>\n",
       "      <td>16.154</td>\n",
       "      <td>17.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17.082</td>\n",
       "      <td>19.932000</td>\n",
       "      <td>12.428</td>\n",
       "      <td>16.182</td>\n",
       "      <td>12.760000</td>\n",
       "      <td>13.153</td>\n",
       "      <td>16.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26565</td>\n",
       "      <td>12.177</td>\n",
       "      <td>17.942000</td>\n",
       "      <td>10.112</td>\n",
       "      <td>15.795</td>\n",
       "      <td>18.572000</td>\n",
       "      <td>16.144</td>\n",
       "      <td>16.066552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26566</td>\n",
       "      <td>14.179</td>\n",
       "      <td>20.564000</td>\n",
       "      <td>10.234</td>\n",
       "      <td>14.450</td>\n",
       "      <td>14.322000</td>\n",
       "      <td>13.146</td>\n",
       "      <td>16.471000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26567</td>\n",
       "      <td>16.437</td>\n",
       "      <td>17.476000</td>\n",
       "      <td>8.668</td>\n",
       "      <td>15.069</td>\n",
       "      <td>16.599000</td>\n",
       "      <td>15.590</td>\n",
       "      <td>14.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26568</td>\n",
       "      <td>17.064</td>\n",
       "      <td>17.814000</td>\n",
       "      <td>14.928</td>\n",
       "      <td>16.273</td>\n",
       "      <td>15.485000</td>\n",
       "      <td>13.624</td>\n",
       "      <td>12.865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26569</td>\n",
       "      <td>15.603</td>\n",
       "      <td>19.703000</td>\n",
       "      <td>11.006</td>\n",
       "      <td>15.875</td>\n",
       "      <td>13.366000</td>\n",
       "      <td>16.527</td>\n",
       "      <td>17.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21458 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       measurement_10  measurement_11  measurement_12  measurement_13  \\\n",
       "id                                                                      \n",
       "0              15.859       17.594000          15.193          15.029   \n",
       "1              17.947       17.915000          11.755          14.732   \n",
       "2              15.607       19.439558          13.798          16.711   \n",
       "3              16.346       18.377000          10.020          15.250   \n",
       "4              17.082       19.932000          12.428          16.182   \n",
       "...               ...             ...             ...             ...   \n",
       "26565          12.177       17.942000          10.112          15.795   \n",
       "26566          14.179       20.564000          10.234          14.450   \n",
       "26567          16.437       17.476000           8.668          15.069   \n",
       "26568          17.064       17.814000          14.928          16.273   \n",
       "26569          15.603       19.703000          11.006          15.875   \n",
       "\n",
       "       measurement_14  measurement_15  measurement_16  \n",
       "id                                                     \n",
       "0           16.110886          13.034       14.684000  \n",
       "1           15.425000          14.395       15.631000  \n",
       "2           18.631000          14.094       17.946000  \n",
       "3           15.562000          16.154       17.172000  \n",
       "4           12.760000          13.153       16.412000  \n",
       "...               ...             ...             ...  \n",
       "26565       18.572000          16.144       16.066552  \n",
       "26566       14.322000          13.146       16.471000  \n",
       "26567       16.599000          15.590       14.065000  \n",
       "26568       15.485000          13.624       12.865000  \n",
       "26569       13.366000          16.527       17.890000  \n",
       "\n",
       "[21458 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스의 0번 수준에 붙은 product_code를 0번 수준을 제거하는 후처리 과정을 통해서도 제거할 수 있습니다.\n",
    "df_basetable.groupby('product_code')[X_mean].apply(lambda x: x.fillna(x.mean())).reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbac8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 2: groupby_ transform(lambda x: fillna ~ )\n",
    "# 1:1 변환이고 Series 별로 처리할 수 있는 경우에는 transform을 사용하면\n",
    "# 불필요하게 groupby의 수준이 붙지 않습니다. \n",
    "X_mean = ['measurement_{}'.format(i) for i in range(10, 17)]\n",
    "df_basetable[X_mean] = \\\n",
    "        df_basetable.groupby('product_code')[X_mean].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaadb4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 3: fillna(groupby ~ transform)\n",
    "# Transform을 통해 수준별 평균으로 1:1 변환된 값으로 구성된 DataFrame을 받아서, \n",
    "# 각각의 요소별로 결측이면 해당값으로 치환되게 구성합니다.\n",
    "df_basetable[X_mean] = \\\n",
    "    df_basetable[X_mean].fillna(df_basetable.groupby('product_code')[X_mean].transform('mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62884d7",
   "metadata": {},
   "source": [
    "Hint] 전처리 단계에서 보간 결과를 확인해 보기 위한 각 변수의 평균과 표본표준편차.\n",
    "\n",
    "| |3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|\n",
    "|-|-|-|-|-|-|-|-|--|--|--|--|--|--|--|--|\n",
    "|mean|17.796|11.736|17.131|17.506|11.719|19.022|11.434|16.034|19.194|11.734|15.666|16.033|15.051|16.398|701.768|\n",
    "|std|0.997|0.994|0.994|0.992|0.993|1.005|0.997|1.278|1.579|1.433|1.149|1.461|1.478|1.671|119.180|\n",
    "\n",
    "열의 이름의 숫자는 measurement_ 번호, 값은 소수점 3째 자리까지 반올림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ff22f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>17.796</td>\n",
       "      <td>11.736</td>\n",
       "      <td>17.131</td>\n",
       "      <td>17.506</td>\n",
       "      <td>11.719</td>\n",
       "      <td>19.022</td>\n",
       "      <td>11.434</td>\n",
       "      <td>16.034</td>\n",
       "      <td>19.194</td>\n",
       "      <td>11.734</td>\n",
       "      <td>15.666</td>\n",
       "      <td>16.033</td>\n",
       "      <td>15.051</td>\n",
       "      <td>16.398</td>\n",
       "      <td>701.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.005</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.278</td>\n",
       "      <td>1.579</td>\n",
       "      <td>1.433</td>\n",
       "      <td>1.149</td>\n",
       "      <td>1.461</td>\n",
       "      <td>1.478</td>\n",
       "      <td>1.671</td>\n",
       "      <td>119.180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           3       4       5       6       7       8       9      10      11  \\\n",
       "mean  17.796  11.736  17.131  17.506  11.719  19.022  11.434  16.034  19.194   \n",
       "std    0.997   0.994   0.994   0.992   0.993   1.005   0.997   1.278   1.579   \n",
       "\n",
       "          12      13      14      15      16       17  \n",
       "mean  11.734  15.666  16.033  15.051  16.398  701.768  \n",
       "std    1.433   1.149   1.461   1.478   1.671  119.180  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basetable[['measurement_{}'.format(i) for i in range(3, 18)]].agg(['mean', 'std'])\\\n",
    "            .applymap(lambda x: round(x, 3))\\\n",
    "            .rename(columns=lambda x: x.split('_')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218dab47",
   "metadata": {},
   "source": [
    "# 문제1\n",
    "\n",
    "(basetable을 사용) measurement_3~16까지 결측 여부가 failure에 영향이 있는지를 파악하고, \n",
    "\n",
    "failure를 분류하는 데 도움이 될 만한 것은 예측 모델의 입력 변수로 사용하고자 한다. \n",
    "\n",
    "이를 위해 전처리 과정에서 뽑아낸 isna_3~16을 활용한다.\n",
    "\n",
    "n이 3부터 16까지, 즉 measurement_3~16까지 다음의 검정을 수행한다. \n",
    "\n",
    "$H_0: P(failure=True|measurement_{n}=Missing)=P(failure=True)$\n",
    "\n",
    "$H_1: P(failure=True|measurement_{n}=Missing) \\neq P(failure=True)$\n",
    "\n",
    "모집단의 $P(failure=True) = 0.2114$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed64b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91304a06",
   "metadata": {},
   "source": [
    "## 단계 1-1\n",
    "\n",
    "우선, measurement_3으로 위 검정을 시행해보자.\n",
    "\n",
    "$H_0: P(failure=True|isna_{3}=True)=0.2114$\n",
    "\n",
    "$H_1: P(failure=True|isna_{3}=True) \\neq 0.2114$\n",
    "\n",
    "으로 바꿀 수 있다.\n",
    "\n",
    "$P(failure=True|isna_{3}=True)$은 표본수가 충분하여 중심극한정리에 의해 정규분포를 따르는 것은 분석가 간에 이견이 없다고 한다. \n",
    "\n",
    "위 검정의 p-value를 구하여 보고 힌트에 주어진 p-value와 비교하여 검정 방법에 문제가 없음을 확인하라.\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats 에서 제공 기능 활용\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n",
    "\n",
    " Hint] p-value는 0.0037(소수점 다섯째 자리에서 반올림하여 넷째 자리까지 표시)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93b98c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, 0.14423076923076922, -2.905807189028007, 0.0036630709140241546)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# 모집단의 failure가 True인 비율(True = 1로 매칭한다면, 평균)\n",
    "P_true = 0.2114\n",
    "# 베르누이 분포의 성질을 이용하면, 모집단의 분산을 구할 수 있습니다. 분산 = p × (1 - p)\n",
    "P_var = P_true * (1 - P_true)\n",
    "\n",
    "# isna_3가 결측인 개수(샘플수)\n",
    "n_sample = df_basetable['isna_3'].sum()\n",
    "# 표본의 평균은 모집단의 평균과 같습니다.\n",
    "P_sam_true = P_true\n",
    "# 표본의 평균 분산은 = 모집단의 분산 / 표본수\n",
    "# 표본의 평균 분산을 구하기 위해 표본의 수를 구합니다. \n",
    "P_sam_var = P_var / n_sample\n",
    "\n",
    "# 표본에서 관측한 비율(평균)을 구합니다.\n",
    "P_ob_true = df_basetable.loc[df_basetable['isna_3'], 'failure'].mean()\n",
    "# 검정통계량을 구합니다. \n",
    "# 양측 검증이라 적용의 편의성을 위해\n",
    "# 표준화 후 좌측 꼬리의 검정통계량을 구하기 위해, 절대값에 마이너스를 취합니다.\n",
    "Z = -abs(P_ob_true - P_sam_true) / (P_sam_var ** 0.5)\n",
    "# 누적분포함수를 이용하여 좌측 꼬리 영역을 구하고 x 2 를 해주어 양쪽 영역을 구합니다.\n",
    "pvalue = norm.cdf(Z) * 2\n",
    "\n",
    "n_sample, P_ob_true, Z, pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c801f8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 표준정규 분포를 이용한 pvalue 도출을 그래프로 설명해봅니다\n",
    "from scipy.stats import norm\n",
    "col = 'isna_{}'.format(4)\n",
    "P_var = P_true * (1 - P_true)\n",
    "n_samples = df_basetable[col].sum()\n",
    "P_missing_true = df_basetable.loc[df_basetable[col], 'failure'].mean()\n",
    "P_missing_var = P_var / n_samples\n",
    "P_missing_std = P_missing_var ** 0.5\n",
    "\n",
    "stat = -abs((P_missing_true - P_true) / P_missing_std)\n",
    "\n",
    "plt.plot(np.linspace(-5, 5, 100), norm.pdf(np.linspace(-5, 5, 100)))\n",
    "plt.axvline(stat, color='red', linestyle='--')\n",
    "plt.text(stat, 0.03, str(stat)[:7])\n",
    "plt.axvline(-stat, color='red', linestyle='--')\n",
    "plt.text(-stat, 0.01, str(-stat)[:6])\n",
    "plt.fill_between(np.linspace(-5, stat, 100), np.zeros(shape=100),\n",
    "                norm.pdf(np.linspace(-5, stat, 100)), color='orange')\n",
    "plt.fill_between(np.linspace(-stat, 5, 100), np.zeros(shape=100),\n",
    "                norm.pdf(np.linspace(-stat, 5, 100)), color='orange')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "892acfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.905807189028007, 0.0036630709140241546)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이론시간에 다루었던 statsmodels의 기능을 활용하여 위 검정을 해봅니다.\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "proportions_ztest(\n",
    "    df_basetable.loc[df_basetable['isna_3'], 'failure'].sum(), # positive(failure=True)인 빈도수\n",
    "    df_basetable['isna_3'].sum(), # 표본의 수\n",
    "    P_true, # 귀무가설에서 제시한 모집단의 비율\n",
    "    'two-sided', # 검정의 종류: 양측 검정\n",
    "    P_true # 베르누이 분포의 분산을 계산할 때의 비율 (모집단의 비율과 동일하게 설정합니다.)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c87c44",
   "metadata": {},
   "source": [
    "## 단계 1-2\n",
    "\n",
    "measuremenet_3을 포함하여 measurement_4 ~ 16까지 위 검정을 반복하고 \n",
    "\n",
    "귀무가설을 기각할 수 있는 경우의 p-value의 합을 A라고 한다. (유의 수준은 5%로 한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f49aa12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* isna_3 312 0.14423076923076922 -2.905807189028007 0.0036630709140241546\n",
      "isna_4 442 0.23755656108597284 -1.3468241702718833 0.17803686833140808\n",
      "* isna_5 565 0.24955752212389382 -2.2213833417706925 0.026325008335499278\n",
      "isna_6 640 0.215625 -0.2617796136561279 0.793491357072205\n",
      "isna_7 766 0.2245430809399478 -0.8909035498642803 0.37298091572329806\n",
      "isna_8 853 0.20164126611957797 -0.6980509343383379 0.48514534123655306\n",
      "isna_9 989 0.21840242669362994 -0.5393439841397007 0.589649524697301\n",
      "isna_10 1059 0.22096317280453256 -0.7622002829475777 0.44594047726157915\n",
      "isna_11 1180 0.21016949152542372 -0.1035248797832757 0.9175464043670771\n",
      "isna_12 1287 0.21833721833721834 -0.6095281379895136 0.5421744277936988\n",
      "isna_13 1395 0.2064516129032258 -0.45265767845606597 0.6507952588133231\n",
      "isna_14 1482 0.21862348178137653 -0.681066949794218 0.49582912857498873\n",
      "isna_15 1603 0.2114784778540237 -0.0076954319495023404 0.9938599942603648\n",
      "isna_16 1708 0.2066744730679157 -0.4783142261813061 0.6324265724265041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['isna_3', 'isna_5']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 반복문을 통하여 나머지 변수에 대해서도 검정을 합니다.\n",
    "\n",
    "P_true = 0.2114\n",
    "P_var = P_true * (1 - P_true)\n",
    "\n",
    "A = 0\n",
    "sel_var = [] # 선택된 변수를 담아 놓습니다.\n",
    "for i in range(3, 17):\n",
    "    col = 'isna_{}'.format(i)\n",
    "    n_sample = df_basetable[col].sum()\n",
    "    P_sam_true = P_true\n",
    "    P_sam_var = P_var / n_sample\n",
    "\n",
    "    P_ob_true = df_basetable.loc[df_basetable[col], 'failure'].mean()\n",
    "\n",
    "    Z = -abs(P_ob_true - P_sam_true) / (P_sam_var ** 0.5)\n",
    "    pvalue = norm.cdf(Z) * 2\n",
    "    if pvalue < 0.05:\n",
    "        A += pvalue # 귀무가설을 기각합니다.\n",
    "        sel_var.append(col)\n",
    "        print('*', col, n_sample, P_ob_true, Z, pvalue)\n",
    "    else:\n",
    "        print(col, n_sample, P_ob_true, Z, pvalue) # 귀무가설을 채택합니다\n",
    "sel_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abeaea54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isna_3 0.003405324556499528\n",
      "isna_4 0.1741657088968988\n",
      "isna_5 0.024516546406520602\n",
      "isna_6 0.7921857087941843\n",
      "isna_7 0.3656339966203622\n",
      "isna_8 0.474635180654421\n",
      "isna_9 0.5827835961630805\n",
      "isna_10 0.4361454068118833\n",
      "isna_11 0.9127039294688549\n",
      "isna_12 0.531745036927435\n",
      "isna_13 0.6372594412899744\n",
      "isna_14 0.48249954404547724\n",
      "isna_15 0.9965691506625175\n",
      "isna_16 0.615410353301508\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "for i in range(3, 17):\n",
    "    print(\n",
    "        'isna_{}'.format(i),\n",
    "        chi2_contingency(\n",
    "            pd.crosstab(\n",
    "                index = df_basetable['isna_{}'.format(i)],\n",
    "                columns = df_basetable['failure']\n",
    "            ), correction=False\n",
    "        )[1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03a86a",
   "metadata": {},
   "source": [
    "## 단계 1-3\n",
    "\n",
    "검정 결과 귀무가설을 기각할 수 있는 경우는 총 두 건이다. \n",
    "\n",
    "해당 파생 변수명의 뒷 자리 번호 순으로 na_1, na_2로 파생 변수를 만들어 prob1 데이터셋을 생성하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "207e8c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029988079249523434"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob1 = df_basetable.assign(\n",
    "    na_1 = df_basetable['isna_3'],\n",
    "    na_2 = df_basetable['isna_5'],\n",
    ")\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33bbf8c",
   "metadata": {},
   "source": [
    "A의 값을 소수점 넷째 자리에서 반올림하여 셋째 자리까지 출력하시오. \n",
    "\n",
    "**0.030**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d2d0f",
   "metadata": {},
   "source": [
    "# 문제 2\n",
    "\n",
    "첫째는 스프링 개발 업체들은 실험이 제품 별로 공정하게 진행이 됐는지를 의문을 가지고 있다.\n",
    "\n",
    "product_code에 따라 개발 업체가 다르다. \n",
    "\n",
    "product_code에 대해서 스프링에 가한 부하(loading)를 동일하게 했는지 조사하라.\n",
    "\n",
    "둘째는, attribute_0와 attribute_1은 스프링을 구성하는 주요 소재이다. \n",
    "\n",
    "failure와는 관계가 없음이 이전에 검증되었다. \n",
    "\n",
    "하지만, 이에 대한 재확인 요청을 받아 attribute_0와 attribute_1은 failure와 상관없음을 확인한다.\n",
    "\n",
    "이를 위해 다음 단계를 수행하라.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb314a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfc21275",
   "metadata": {},
   "source": [
    "## 단계 2-1\n",
    "\n",
    "prob1에서 입력 변수 loading에 결측이 없는 행들을 뽑아 prob2 데이터프레임을 만든다.\n",
    "\n",
    "Hint] prob2의 데이터 수는 21,257 이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2ef461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob2 = df_prob1.loc[df_prob1['loading'].notna()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ebf527",
   "metadata": {},
   "source": [
    "## 단계 2-2\n",
    "\n",
    "prob2에 loading의 각 행들에 자연 로그 함수를 적용하여 파생 변수 loading_log를 만든다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb0152db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob2['loading_log'] = np.log(df_prob2['loading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ab15b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 로그 변환이 어떤 효과를 보였는지, 보여주기 위한 참고용 코드입니다.\n",
    "# 좌측으로 치우친 loading 변수가 log 변환을 통해 좌우 대칭형으로 변환되었음을 확인할 수 있습니다.\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 3) )\n",
    "sns.histplot(data=df_prob2, x='loading', ax=axes[0])\n",
    "sns.histplot(data=df_prob2, x='loading_log', ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2245b2",
   "metadata": {},
   "source": [
    "## 단계 2-3\n",
    "\n",
    "loading_log가 product_code 각각에 대해서 정규성을 지니고 있는지 확인하고자 한다.\n",
    "\n",
    "이를 위해 product_code 별로 loading_log에 대한 Jarque-Bera로 검정하고, \n",
    "\n",
    "검정 결과 정규성을 부정할 수 경우의 product_code의 수를 B라고 한다.(유의 수준: 5%)\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats 에서 제공 기능 활용\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "713ee8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jarque_beraResult(statistic=1.467731470333654, pvalue=0.4800496537264637)\n",
      "Jarque_beraResult(statistic=0.6168837955943998, pvalue=0.7345906322931469)\n",
      "Jarque_beraResult(statistic=7.536229242478234, pvalue=0.023095566154546443)\n",
      "Jarque_beraResult(statistic=0.04839464502051384, pvalue=0.9760930856160965)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1: 반복문을 이용해봅니다.\n",
    "from scipy.stats import jarque_bera\n",
    "B = 0\n",
    "for i in df_prob2['product_code'].unique():\n",
    "    result_jb = jarque_bera(df_prob2.loc[df_prob2['product_code'] == i, 'loading_log'])\n",
    "    print(result_jb)\n",
    "    if result_jb.pvalue > 0.05:\n",
    "        B += 1\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60bd8734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>pvalue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>A</td>\n",
       "      <td>1.467731</td>\n",
       "      <td>0.480050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>0.616884</td>\n",
       "      <td>0.734591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C</td>\n",
       "      <td>7.536229</td>\n",
       "      <td>0.023096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>E</td>\n",
       "      <td>0.048395</td>\n",
       "      <td>0.976093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              statistic    pvalue\n",
       "product_code                     \n",
       "A              1.467731  0.480050\n",
       "B              0.616884  0.734591\n",
       "C              7.536229  0.023096\n",
       "E              0.048395  0.976093"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법2: groupby를 이용해봅니다.\n",
    "from scipy.stats import jarque_bera\n",
    "# pvalue만을 구하면 되지만, \n",
    "# Dataframe 처리 연습을 위해 statistic까지 구하여 DataFrame의 내용을 구성해가는 연습을 해봅니다.\n",
    "df_jarque = df_prob2.groupby('product_code')['loading_log']\\\n",
    "        .apply(lambda x: pd.Series(jarque_bera(x), index=['statistic', 'pvalue']))\\\n",
    "        .unstack()\n",
    "B = len(df_jarque.query('pvalue >= 0.05'))\n",
    "display(df_jarque)\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7e5cf",
   "metadata": {},
   "source": [
    "## 단계 2-4\n",
    "\n",
    "loading_log 변수를 product_code로 구분했을 때, \n",
    "\n",
    "등분산성을 보이는지 Bartlett 검정을 통해 확인한다.\n",
    "\n",
    "검정 결과에서 p-value를 C라고 한다.\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats 에서 제공 기능 활용\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec4d8245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartlettResult(statistic=1.928667047072185, pvalue=0.5873433093297675)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1: 하드코딩입니다.\n",
    "from scipy.stats import bartlett\n",
    "bartlett(\n",
    "    df_prob2.loc[df_prob2['product_code'] == 'A', 'loading_log'],\n",
    "    df_prob2.loc[df_prob2['product_code'] == 'B', 'loading_log'],\n",
    "    df_prob2.loc[df_prob2['product_code'] == 'C', 'loading_log'],\n",
    "    df_prob2.loc[df_prob2['product_code'] == 'E', 'loading_log']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76ec2d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5873433093297675,\n",
       " BartlettResult(statistic=1.928667047072185, pvalue=0.5873433093297675))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법2: groupby와 list unpacking(* operator)을 이용해 봅니다.\n",
    "result = bartlett(*df_prob2.groupby('product_code')['loading_log'].agg(list))\n",
    "C = result.pvalue\n",
    "C, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b058c6b2",
   "metadata": {},
   "source": [
    "## 단계 2-5\n",
    "\n",
    "product_code에 대한 분산분석(ANOVA)을 통해서 loading_log 평균에 차이가 있는지 검정한다.\n",
    "\n",
    "그 결과 중 p-value를 D라고 한다.\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats 제공 기능 활용\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec47f9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(F_onewayResult(statistic=0.37177284134760413, pvalue=0.7733782072320899),\n",
       " 0.7733782072320899)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 일원산분산분석은 scipy.stats의 함수로 제공되고 있습니다.\n",
    "# 함수명이 직관적이지 않습니다. 일원산(oneway) 분산분석(f분포사용 ) => f_oneway\n",
    "# bartlett에서 사용했던 groupby ~ agg(list) 방법을 응용해봅니다.\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "result = f_oneway(\n",
    "    *df_prob2.groupby('product_code')['loading_log'].agg(list)\n",
    ")\n",
    "D = result.pvalue\n",
    "result, D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad8e9f4",
   "metadata": {},
   "source": [
    "**Tip!**  일원산 분산분석을 직접 해봅니다.\n",
    "\n",
    "GroupBy에 대한 활용법을 더 알아보고, \n",
    "\n",
    "ANOVA에 대한 이해를 공고히 해보기 위해 예를 들어 보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c224727c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7733782072321986, 0.7733782072320899)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 통계량 F = MSR/MSE를 구하기 위해서는, \n",
    "# SSR, SSE와 SSR에서의 자유도(df1), SSE에서의 자유도(df2)를 구합니다.\n",
    "# 이를 통해, MSR, MSE를 구합니다.\n",
    "from scipy.stats import f\n",
    "\n",
    "# SSR, SSE를 구하기 위해 평균을 구합니다.\n",
    "x_mean = df_prob2['loading_log'].mean()\n",
    "# df1 = 수준의 수 - 1\n",
    "df1 = df_prob2['product_code'].nunique() - 1\n",
    "# df2 = 데이터의 수 - 수준의 수\n",
    "df2 = len(df_prob2) - df_prob2['product_code'].nunique()\n",
    "# SSR은 (예측값(수준별 평균) - 평균) ** 2의 합입니다.\n",
    "SSR = df_prob2.groupby('product_code')['loading_log'].transform(lambda x: (x.mean() - x_mean) ** 2).sum()\n",
    "MSR = SSR / df1\n",
    "# SSE는 (예측값(수준별 평균) - 실제값) ** 2의 합입니다.\n",
    "SSE = df_prob2.groupby('product_code')['loading_log'].transform(lambda x: (x.mean() - x) ** 2).sum()\n",
    "MSE = SSE / df2\n",
    "\n",
    "# 분산분석은 우측 검정입니다.\n",
    "F = MSR / MSE\n",
    "1 - f.cdf(F, df1, df2), f.sf(F, df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fdafc7",
   "metadata": {},
   "source": [
    "**Group By: apply, transform, agg 비교입니다.**\n",
    "\n",
    "apply와 transform은 Series에 대해 1:1 변환일 경우에는 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e9395e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0       -1.399622\n",
       "1       -1.205924\n",
       "2       -1.303996\n",
       "3       -0.624109\n",
       "4        1.446752\n",
       "           ...   \n",
       "26565    0.883971\n",
       "26566    0.598356\n",
       "26567   -0.187450\n",
       "26568   -0.467832\n",
       "26569    0.238094\n",
       "Name: loading_log, Length: 21257, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ex) apply를 통한 product_code별 loading_log의 표준화\n",
    "df_prob2.groupby('product_code')['loading_log'].apply(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2661c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0       -1.399622\n",
       "1       -1.205924\n",
       "2       -1.303996\n",
       "3       -0.624109\n",
       "4        1.446752\n",
       "           ...   \n",
       "26565    0.883971\n",
       "26566    0.598356\n",
       "26567   -0.187450\n",
       "26568   -0.467832\n",
       "26569    0.238094\n",
       "Name: loading_log, Length: 21257, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ex) transform를 통한 product_code별 loading_log의 표준화\n",
    "df_prob2.groupby('product_code')['loading_log'].transform(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca66a7",
   "metadata": {},
   "source": [
    "apply를 통해 하나의 값으로 집계를 낸다면(N:1), agg 와 같게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f1c2d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_code\n",
       "A    4.802952\n",
       "B    4.803357\n",
       "C    4.808219\n",
       "E    4.805994\n",
       "Name: loading_log, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ex) apply에서 하나의 값으로 집계를 냅니다.\n",
    "df_prob2.groupby('product_code')['loading_log'].apply(lambda x: x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4e1d393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0        4.802952\n",
       "1        4.802952\n",
       "2        4.802952\n",
       "3        4.802952\n",
       "4        4.802952\n",
       "           ...   \n",
       "26565    4.805994\n",
       "26566    4.805994\n",
       "26567    4.805994\n",
       "26568    4.805994\n",
       "26569    4.805994\n",
       "Name: loading_log, Length: 21257, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ex) transform에서 하나의 값으로 집계를 낸다면, 각각의 수준이 집계를 낸 값으로 변환되게 됩니다.\n",
    "df_prob2.groupby('product_code')['loading_log'].transform(lambda x: x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44cbbe2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_code\n",
       "A    4.802952\n",
       "B    4.803357\n",
       "C    4.808219\n",
       "E    4.805994\n",
       "Name: loading_log, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ex) 이 때는, apply는 agg와 동일한 연산이 됩니다.\n",
    "df_prob2.groupby('product_code')['loading_log'].agg(lambda x: x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c23d2c",
   "metadata": {},
   "source": [
    "## 단계 2-6\n",
    "\n",
    "카이제곱검정을 통해 attribute_0, attribute_1의 결합값이 failure와 연관이 있는지 조사하라. \n",
    "\n",
    "attribute_0, attribute_1의 결합값의 의미 attribute_0=material_7, attribute_1=material_8 이라면, 이 둘의 결합값은\n",
    "matertial_7material_8를 의미한다.\n",
    "\n",
    "(유의 수준 1%) 연관이 있다면 E값은 1 없으면 0으로 한다.\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats.chi2_contingency, correction=False\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b3530be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7.0400463075335615,\n",
       "  0.029598749837407304,\n",
       "  2,\n",
       "  array([[4106.03584702, 1102.96415298],\n",
       "         [4162.79042198, 1118.20957802],\n",
       "         [8487.17373101, 2279.82626899]])),\n",
       " 0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H0: 독립 o, 연립 x, H1: 독립 x, 연관 o\n",
    "from scipy.stats import chi2_contingency\n",
    "result = chi2_contingency(\n",
    "    pd.crosstab(\n",
    "        index=df_prob2['attribute_0'] + df_prob2['attribute_1'],\n",
    "        columns=df_prob2['failure']\n",
    "    ), correction=False\n",
    ")\n",
    "\n",
    "E = 0 if result[1] >= 0.01 else 1\n",
    "result, E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8eb98",
   "metadata": {},
   "source": [
    "**Tip!** Chi2 검정도 직접해봅니다.\n",
    "\n",
    "$chi2 = \\sum_{i,j}\\frac{(E_{ij} - O_{ij})^2}{E_{ij}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9288d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>material_7material_8</td>\n",
       "      <td>8487.173731</td>\n",
       "      <td>2279.826269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>material_7material_6</td>\n",
       "      <td>4162.790422</td>\n",
       "      <td>1118.209578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>material_5material_5</td>\n",
       "      <td>4106.035847</td>\n",
       "      <td>1102.964153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0            1\n",
       "material_7material_8  8487.173731  2279.826269\n",
       "material_7material_6  4162.790422  1118.209578\n",
       "material_5material_5  4106.035847  1102.964153"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7.040046307533586, 0.029598749837406936, 0.029598749837406957, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "# 직접하기 위해서는 예측 빈도수 테이블이 필요합니다.\n",
    "# index에 해당하는 변수의 빈도수와\n",
    "# column에 해당하는 변수의 비율(value_counts(normalize=True))을 행렬곱을 하면 구할 수 있습니다.\n",
    "# pandas의 행렬곱은 dot에서 제공되고 있으면, caller의 열이름과 callee의 인덱스를 기준으로 연산을 합니다. \n",
    "# 이를 일치시켜 주기위해 rename('val')을 해줍니다.\n",
    "df_expect = (df_prob2['attribute_0'] + df_prob2['attribute_1']).value_counts().rename('val').to_frame().dot(\n",
    "    df_prob2['failure'].value_counts(normalize=True).rename('val').to_frame().T\n",
    ")\n",
    "df_ob = pd.crosstab(\n",
    "    index=df_prob2['attribute_0'] + df_prob2['attribute_1'],\n",
    "    columns=df_prob2['failure']\n",
    ")\n",
    "# chi2 검정에서의 자유도: 빈도수테이블의 (행의 수 - 1) × (열의 수  -1)  = (3 - 1) × (2 - 1) = 2\n",
    "df = ((df_prob2['attribute_0'] + df_prob2['attribute_1']).nunique() - 1) * (df_prob2['failure'].nunique() - 1)\n",
    "# 검정 통계량을 구합니다.\n",
    "CHI2 = ((df_expect - df_ob) ** 2 / df_expect).sum().sum()\n",
    "display(df_expect)\n",
    "# chi2 독립성 검정은 우측 검정입니다.\n",
    "CHI2, chi2.sf(CHI2, df), 1 - chi2.cdf(CHI2, df), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f75a36d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.5873433093297675, 0.7733782072320899, 0, 4.360721516561858)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, C, D, E, B + C + D + E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42805f",
   "metadata": {},
   "source": [
    "B + C + D + E의 값을 소수점 셋째 자리에서 반올림하여 둘째 자리까지 출력하시오.\n",
    "\n",
    "**4.36**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe1afc",
   "metadata": {},
   "source": [
    "# 문제 3\n",
    "\n",
    "로지스틱 회귀모델로 수치형 변수 measurement_0 ~ 17, \n",
    "\n",
    "loading과 이진형인 na_1, na_2 중에서 최적의 성능을 보이는 입력 변수들을 찾고자 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a63c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1ec19e2",
   "metadata": {},
   "source": [
    "## 단계 3-1\n",
    "\n",
    "prob1을 복사하여 prob3을 만든다. loading의 결측치는 loading의 평균으로 대치한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74e376a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_code      0\n",
       "loading           0\n",
       "attribute_0       0\n",
       "attribute_1       0\n",
       "attribute_2       0\n",
       "attribute_3       0\n",
       "measurement_0     0\n",
       "measurement_1     0\n",
       "measurement_2     0\n",
       "measurement_3     0\n",
       "measurement_4     0\n",
       "measurement_5     0\n",
       "measurement_6     0\n",
       "measurement_7     0\n",
       "measurement_8     0\n",
       "measurement_9     0\n",
       "measurement_10    0\n",
       "measurement_11    0\n",
       "measurement_12    0\n",
       "measurement_13    0\n",
       "measurement_14    0\n",
       "measurement_15    0\n",
       "measurement_16    0\n",
       "measurement_17    0\n",
       "failure           0\n",
       "isna_3            0\n",
       "isna_4            0\n",
       "isna_5            0\n",
       "isna_6            0\n",
       "isna_7            0\n",
       "isna_8            0\n",
       "isna_9            0\n",
       "isna_10           0\n",
       "isna_11           0\n",
       "isna_12           0\n",
       "isna_13           0\n",
       "isna_14           0\n",
       "isna_15           0\n",
       "isna_16           0\n",
       "isna_17           0\n",
       "na_1              0\n",
       "na_2              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob3 = df_prob1.copy()\n",
    "df_prob3['loading'] = df_prob3['loading'].fillna(df_prob3['loading'].mean())\n",
    "df_prob3.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb5594",
   "metadata": {},
   "source": [
    "## 단계 3-2: \n",
    "    \n",
    "prob3를 80%는 학습데이터 prob3_train으로 20%는 테스트데이터 prob3_test로 나눈다. \n",
    "\n",
    "prob3_train의 failure가 1인 비율과 prob3_test의 failure가 1의 비율을 동일하게 한다.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " sklearn.model_selection.train_test_split, random_state=123, \n",
    " \n",
    " train과 test의 failure의 비율은 stratify 매개 변수를 이용하여 맞춘다.\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac987b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# stratify에 비율을 맞추고자 하는 변수(pd.Series, np.array ... )를 넣어주면 층화 분리를 합니다.\n",
    "df_prob3_train, df_prob3_test = train_test_split(\n",
    "    df_prob3, train_size=0.8, random_state=123, stratify=df_prob3['failure']\n",
    ")\n",
    "df_prob3_train, df_prob3_test = df_prob3_train.copy(), df_prob3_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7716c3a",
   "metadata": {},
   "source": [
    "## 단계 3-3\n",
    "\n",
    "prob3_train의 수치형 입력 변수 loading, measurement_0 ~ 17을 표준화한다. \n",
    "\n",
    "prob3_train의 표준화 설정으로 prob3_test의 loading, measurement_0 ~ 17에도 적용한다. \n",
    "\n",
    "표준화 처리한 prob3_train과 prob3_test는 문제 4와 문제 5에서 사용한다.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " sklearn.preprocessing 제공 기능 활용, \n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf17f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "X_std = ['loading'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "df_prob3_train[X_std] = std_scaler.fit_transform(df_prob3_train[X_std])\n",
    "df_prob3_test[X_std] = std_scaler.transform(df_prob3_test[X_std])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20b6ef8",
   "metadata": {},
   "source": [
    "## 단계 3-4\n",
    "    \n",
    "로지스틱 회귀모델을 사용하여 loading, measurement_0~17과 na_1, na_2를 입력 변수로 하여 prob3_train을 학습한다. \n",
    "\n",
    "로지스틱 회귀모델을 prob3_test로 성능을 측정한 값을 A라고 한다.\n",
    "\n",
    "입력 변수: loading, measurement_0~17, na_1, na_2\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC(area under of ROC curve)\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " sklearn.linear_model.LogisticRegression, solver='lbfgs', 문제 지시사항 외 Default 값 사용\n",
    " \n",
    " sklearn.metrics.roc_auc_score\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fb86e3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5952982435574312, 0.5792951262053387)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_lr = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "clf_lr = LogisticRegression(\n",
    "    solver='lbfgs'\n",
    ")\n",
    "clf_lr.fit(df_prob3_train[X_lr], df_prob3_train['failure'])\n",
    "A = roc_auc_score(\n",
    "    df_prob3_test['failure'], \n",
    "    clf_lr.predict_proba(df_prob3_test[X_lr])[:, 1]\n",
    ")\n",
    "(\n",
    "    roc_auc_score(\n",
    "        df_prob3_train['failure'], \n",
    "        clf_lr.predict_proba(df_prob3_train[X_lr])[:, 1]\n",
    "    ), A\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38200f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5792951262053387"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(\n",
    "    df_prob3_test['failure'], \n",
    "    clf_lr.decision_function(df_prob3_test[X_lr])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "336279e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5778277926972065"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(\n",
    "    df_prob3_test['failure'], \n",
    "    df_prob3_test['loading']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e0038140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot([0, 1], [0, 1], color='orange', linestyle='--')\n",
    "df_prob3_test[['failure']].assign(\n",
    "    score = clf_lr.decision_function(df_prob3_test[X_lr])\n",
    ").sort_values('score', ascending=False).assign(\n",
    "    fpr=lambda x: (1-x['failure']).cumsum() / (1 - x['failure']).sum(),\n",
    "    tpr=lambda x: (x['failure']).cumsum() / ( x['failure']).sum(),\n",
    ").groupby('tpr', as_index=False)['fpr'].max()\\\n",
    ".groupby('fpr', as_index=False)['tpr'].max()\\\n",
    ".pipe(\n",
    "    lambda x: plt.plot(x['fpr'], x['tpr'])\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cba372a",
   "metadata": {},
   "source": [
    "## 단계 3-5\n",
    "\n",
    "loading, measurement_0 ~ 17, na_1, na_2를 후보 입력 변수로 한다. \n",
    "\n",
    "전진 선택법을 사용하여 이 후보 입력 변수 중에서 최적의 성능을 보이는 입력 변수의 조합을 찾는다. \n",
    "\n",
    "전진 선택법의 선택 기준은 prob3_train을 대상으로 5겹 층화교차검증(5-Fold stratified cross validation)을 하고 \n",
    "\n",
    "겹외(OOF, Out-Of Fold) 성능의 평균값으로 한다. 전진 선택 과정에서 선택했던 변수를 제외하지 않는다. \n",
    "\n",
    "입력 변수: 본 단계 요건 참고\n",
    "\n",
    "대상 변수: failure \n",
    "\n",
    "성능 지표: AUC(area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "mlxtend.feature_selection.SequentialFeatureSelector\n",
    "\n",
    "sklearn.linear_model.LogisticRegression, solver='lbfgs'\n",
    "\n",
    "sklearn.metrics.roc_auc_score\n",
    "\n",
    "sklearn.model_selection.StratifiedKFold, random_state=123, shuffle=True\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9713233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\student\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(clone_estimator=True,\n",
       "                          cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
       "                          estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                       dual=False,\n",
       "                                                       fit_intercept=True,\n",
       "                                                       intercept_scaling=1,\n",
       "                                                       l1_ratio=None,\n",
       "                                                       max_iter=100,\n",
       "                                                       multi_class='warn',\n",
       "                                                       n_jobs=None,\n",
       "                                                       penalty='l2',\n",
       "                                                       random_state=None,\n",
       "                                                       solver='lbfgs',\n",
       "                                                       tol=0.0001, verbose=0,\n",
       "                                                       warm_start=False),\n",
       "                          floating=False, forward=True, k_features='best',\n",
       "                          n_jobs=1, pre_dispatch='2*n_jobs', scoring='roc_auc',\n",
       "                          verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X_sfs = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "sfs = SequentialFeatureSelector(\n",
    "    estimator=LogisticRegression(solver='lbfgs'),\n",
    "    forward=True, # 전진 선택법을 사용하여 \n",
    "    k_features=\"best\", # 이 후보 입력 변수 중에서 최적의 성능\n",
    "    cv=StratifiedKFold(5, random_state=123, shuffle=True), # 5겹 층화교차검증(5-Fold stratified cross validation), 겹외(OOF, Out-Of Fold) 성능의 평균값으로 한다. \n",
    "    floating=False, # 전진 선택 과정에서 선택했던 변수를 제외하지 않는다.\n",
    "    scoring='roc_auc' # score / error neg_mean_absolute_error\n",
    ")\n",
    "sfs.fit(df_prob3_train[X_sfs], df_prob3_train['failure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9b236f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('loading',\n",
       "  'measurement_1',\n",
       "  'measurement_4',\n",
       "  'measurement_14',\n",
       "  'measurement_17',\n",
       "  'na_1'),\n",
       " 0.5917537024093409)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.k_feature_names_, sfs.k_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f214c746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'feature_idx': (0,),\n",
       "  'cv_scores': array([0.60037345, 0.57115188, 0.58550503, 0.58230804, 0.60340806]),\n",
       "  'avg_score': 0.5885492900130771,\n",
       "  'feature_names': ('loading',)},\n",
       " 2: {'feature_idx': (0, 18),\n",
       "  'cv_scores': array([0.60267405, 0.57143555, 0.58795125, 0.58050448, 0.60829591]),\n",
       "  'avg_score': 0.5901722458803432,\n",
       "  'feature_names': ('loading', 'measurement_17')},\n",
       " 3: {'feature_idx': (0, 5, 18),\n",
       "  'cv_scores': array([0.60560384, 0.56745342, 0.59135025, 0.58167225, 0.60799722]),\n",
       "  'avg_score': 0.5908153976487898,\n",
       "  'feature_names': ('loading', 'measurement_4', 'measurement_17')},\n",
       " 4: {'feature_idx': (0, 2, 5, 18),\n",
       "  'cv_scores': array([0.60829203, 0.56526443, 0.58923045, 0.58339007, 0.60951609]),\n",
       "  'avg_score': 0.5911386131847978,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_1',\n",
       "   'measurement_4',\n",
       "   'measurement_17')},\n",
       " 5: {'feature_idx': (0, 2, 5, 18, 19),\n",
       "  'cv_scores': array([0.60964655, 0.56444317, 0.59139146, 0.58382766, 0.60829642]),\n",
       "  'avg_score': 0.5915210536302331,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_1',\n",
       "   'measurement_4',\n",
       "   'measurement_17',\n",
       "   'na_1')},\n",
       " 6: {'feature_idx': (0, 2, 5, 15, 18, 19),\n",
       "  'cv_scores': array([0.61088307, 0.56618796, 0.58814816, 0.58388567, 0.60966365]),\n",
       "  'avg_score': 0.5917537024093409,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_1',\n",
       "   'measurement_4',\n",
       "   'measurement_14',\n",
       "   'measurement_17',\n",
       "   'na_1')},\n",
       " 7: {'feature_idx': (0, 2, 3, 5, 15, 18, 19),\n",
       "  'cv_scores': array([0.60960027, 0.56712014, 0.58806115, 0.58466469, 0.60889023]),\n",
       "  'avg_score': 0.5916672956050881,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_4',\n",
       "   'measurement_14',\n",
       "   'measurement_17',\n",
       "   'na_1')},\n",
       " 8: {'feature_idx': (0, 1, 2, 3, 5, 15, 18, 19),\n",
       "  'cv_scores': array([0.61044004, 0.56535449, 0.58867481, 0.58513536, 0.60899352]),\n",
       "  'avg_score': 0.5917196433419487,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_0',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_4',\n",
       "   'measurement_14',\n",
       "   'measurement_17',\n",
       "   'na_1')},\n",
       " 9: {'feature_idx': (0, 1, 2, 3, 4, 5, 15, 18, 19),\n",
       "  'cv_scores': array([0.61039579, 0.56491079, 0.58863257, 0.58522695, 0.60896553]),\n",
       "  'avg_score': 0.5916263266705529,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_0',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_3',\n",
       "   'measurement_4',\n",
       "   'measurement_14',\n",
       "   'measurement_17',\n",
       "   'na_1')},\n",
       " 10: {'feature_idx': (0, 1, 2, 3, 4, 5, 7, 15, 18, 19),\n",
       "  'cv_scores': array([0.61083119, 0.56344026, 0.58886257, 0.58502851, 0.60937107]),\n",
       "  'avg_score': 0.5915067187872627,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_0',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_3',\n",
       "   'measurement_4',\n",
       "   'measurement_6',\n",
       "   'measurement_14',\n",
       "   'measurement_17',\n",
       "   'na_1')},\n",
       " 11: {'feature_idx': (0, 1, 2, 3, 4, 5, 7, 8, 15, 18, 19),\n",
       "  'cv_scores': array([0.6107259 , 0.56341482, 0.58825146, 0.58472626, 0.60945045]),\n",
       "  'avg_score': 0.5913137771575298,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_0',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_3',\n",
       "   'measurement_4',\n",
       "   'measurement_6',\n",
       "   'measurement_7',\n",
       "   'measurement_14',\n",
       "   'measurement_17',\n",
       "   'na_1')},\n",
       " 12: {'feature_idx': (0, 1, 2, 3, 4, 5, 6, 7, 8, 15, 18, 19),\n",
       "  'cv_scores': array([0.61076099, 0.56317821, 0.58823975, 0.58430648, 0.60895434]),\n",
       "  'avg_score': 0.5910879545549661,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_0',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_3',\n",
       "   'measurement_4',\n",
       "   'measurement_5',\n",
       "   'measurement_6',\n",
       "   'measurement_7',\n",
       "   'measurement_14',\n",
       "   'measurement_17',\n",
       "   'na_1')},\n",
       " 13: {'feature_idx': (0, 1, 2, 3, 4, 5, 6, 7, 8, 15, 17, 18, 19),\n",
       "  'cv_scores': array([0.61109416, 0.56308764, 0.58649649, 0.5843253 , 0.60912174]),\n",
       "  'avg_score': 0.5908250669005813,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_0',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_3',\n",
       "   'measurement_4',\n",
       "   'measurement_5',\n",
       "   'measurement_6',\n",
       "   'measurement_7',\n",
       "   'measurement_14',\n",
       "   'measurement_16',\n",
       "   'measurement_17',\n",
       "   'na_1')},\n",
       " 14: {'feature_idx': (0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 15, 17, 18, 19),\n",
       "  'cv_scores': array([0.61094563, 0.56271059, 0.58619883, 0.5838526 , 0.60905865]),\n",
       "  'avg_score': 0.5905532593766387,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_0',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_3',\n",
       "   'measurement_4',\n",
       "   'measurement_5',\n",
       "   'measurement_6',\n",
       "   'measurement_7',\n",
       "   'measurement_10',\n",
       "   'measurement_14',\n",
       "   'measurement_16',\n",
       "   'measurement_17',\n",
       "   'na_1')},\n",
       " 15: {'feature_idx': (0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 15, 17, 18, 19),\n",
       "  'cv_scores': array([0.61105194, 0.56244498, 0.58597799, 0.58321249, 0.60873503]),\n",
       "  'avg_score': 0.5902844860221045,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_0',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_3',\n",
       "   'measurement_4',\n",
       "   'measurement_5',\n",
       "   'measurement_6',\n",
       "   'measurement_7',\n",
       "   'measurement_10',\n",
       "   'measurement_12',\n",
       "   'measurement_14',\n",
       "   'measurement_16',\n",
       "   'measurement_17',\n",
       "   'na_1')},\n",
       " 16: {'feature_idx': (0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 15, 17, 18, 19, 20),\n",
       "  'cv_scores': array([0.61214502, 0.56220532, 0.5858691 , 0.58423015, 0.60545662]),\n",
       "  'avg_score': 0.5899812426631774,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_0',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_3',\n",
       "   'measurement_4',\n",
       "   'measurement_5',\n",
       "   'measurement_6',\n",
       "   'measurement_7',\n",
       "   'measurement_10',\n",
       "   'measurement_12',\n",
       "   'measurement_14',\n",
       "   'measurement_16',\n",
       "   'measurement_17',\n",
       "   'na_1',\n",
       "   'na_2')},\n",
       " 17: {'feature_idx': (0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   11,\n",
       "   13,\n",
       "   15,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20),\n",
       "  'cv_scores': array([0.61155702, 0.56213103, 0.58598104, 0.58256067, 0.6051498 ]),\n",
       "  'avg_score': 0.5894759133397836,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_0',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_3',\n",
       "   'measurement_4',\n",
       "   'measurement_5',\n",
       "   'measurement_6',\n",
       "   'measurement_7',\n",
       "   'measurement_8',\n",
       "   'measurement_10',\n",
       "   'measurement_12',\n",
       "   'measurement_14',\n",
       "   'measurement_16',\n",
       "   'measurement_17',\n",
       "   'na_1',\n",
       "   'na_2')},\n",
       " 18: {'feature_idx': (0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   11,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20),\n",
       "  'cv_scores': array([0.61196089, 0.55878851, 0.58604109, 0.58232763, 0.60572783]),\n",
       "  'avg_score': 0.5889691877700873,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_0',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_3',\n",
       "   'measurement_4',\n",
       "   'measurement_5',\n",
       "   'measurement_6',\n",
       "   'measurement_7',\n",
       "   'measurement_8',\n",
       "   'measurement_10',\n",
       "   'measurement_12',\n",
       "   'measurement_13',\n",
       "   'measurement_14',\n",
       "   'measurement_16',\n",
       "   'measurement_17',\n",
       "   'na_1',\n",
       "   'na_2')},\n",
       " 19: {'feature_idx': (0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20),\n",
       "  'cv_scores': array([0.61279405, 0.55895999, 0.58550936, 0.58045359, 0.60450663]),\n",
       "  'avg_score': 0.5884447231004424,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_0',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_3',\n",
       "   'measurement_4',\n",
       "   'measurement_5',\n",
       "   'measurement_6',\n",
       "   'measurement_7',\n",
       "   'measurement_8',\n",
       "   'measurement_9',\n",
       "   'measurement_10',\n",
       "   'measurement_12',\n",
       "   'measurement_13',\n",
       "   'measurement_14',\n",
       "   'measurement_16',\n",
       "   'measurement_17',\n",
       "   'na_1',\n",
       "   'na_2')},\n",
       " 20: {'feature_idx': (0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20),\n",
       "  'cv_scores': array([0.6121145 , 0.5580619 , 0.58406732, 0.58034369, 0.60451884]),\n",
       "  'avg_score': 0.5878212495585312,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_0',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_3',\n",
       "   'measurement_4',\n",
       "   'measurement_5',\n",
       "   'measurement_6',\n",
       "   'measurement_7',\n",
       "   'measurement_8',\n",
       "   'measurement_9',\n",
       "   'measurement_10',\n",
       "   'measurement_11',\n",
       "   'measurement_12',\n",
       "   'measurement_13',\n",
       "   'measurement_14',\n",
       "   'measurement_16',\n",
       "   'measurement_17',\n",
       "   'na_1',\n",
       "   'na_2')},\n",
       " 21: {'feature_idx': (0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20),\n",
       "  'cv_scores': array([0.61192935, 0.55740601, 0.58412533, 0.58013608, 0.60244433]),\n",
       "  'avg_score': 0.5872082214451655,\n",
       "  'feature_names': ('loading',\n",
       "   'measurement_0',\n",
       "   'measurement_1',\n",
       "   'measurement_2',\n",
       "   'measurement_3',\n",
       "   'measurement_4',\n",
       "   'measurement_5',\n",
       "   'measurement_6',\n",
       "   'measurement_7',\n",
       "   'measurement_8',\n",
       "   'measurement_9',\n",
       "   'measurement_10',\n",
       "   'measurement_11',\n",
       "   'measurement_12',\n",
       "   'measurement_13',\n",
       "   'measurement_14',\n",
       "   'measurement_15',\n",
       "   'measurement_16',\n",
       "   'measurement_17',\n",
       "   'na_1',\n",
       "   'na_2')}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65b3721a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loading',\n",
       " 'measurement_1',\n",
       " 'measurement_4',\n",
       " 'measurement_14',\n",
       " 'measurement_17',\n",
       " 'na_1']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_best = list(sfs.k_feature_names_)\n",
    "X_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c6893",
   "metadata": {},
   "source": [
    "## 단계 3-6\n",
    "\n",
    "단계 3-5에서 찾은 최적의 입력 변수 조합으로 로지스틱 회귀모델을 사용하여 prob3_train을 학습하고 \n",
    "\n",
    "prob3_test로 성능을 측정한 값을 B라고 한다.\n",
    "\n",
    "입력 변수: **단계 3-5**에서 도출한 최적의 입력 변수 조합\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC(area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수 가이드**\n",
    "\n",
    "sklearn.linear_model.LogisticRegression, solver='lbfgs'\n",
    "\n",
    "sklearn.metrics.roc_auc_score\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d96e152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5936682060775388, 0.5838326230092876)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf_lr = LogisticRegression(\n",
    "    solver='lbfgs'\n",
    ")\n",
    "clf_lr.fit(df_prob3_train[X_best], df_prob3_train['failure'])\n",
    "B = roc_auc_score(\n",
    "    df_prob3_test['failure'], \n",
    "    clf_lr.predict_proba(df_prob3_test[X_best])[:, 1]\n",
    ")\n",
    "(\n",
    "    roc_auc_score(\n",
    "        df_prob3_train['failure'], \n",
    "        clf_lr.predict_proba(df_prob3_train[X_best])[:, 1]\n",
    "    ), B\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a19d42ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.004537496803948882"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A - B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac40eec",
   "metadata": {},
   "source": [
    "A-B값을 소수점 넷째 자리에서 반올림하여 셋째 자리까지 출력하시오\n",
    "\n",
    "**-0.005**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed67461",
   "metadata": {},
   "source": [
    "# 문제 4\n",
    "\n",
    "차원 축소 기법을 통한 데이터의 특성과 failure 분류 성능을 높힐 만한 요소를 살펴 본다. \n",
    "\n",
    "첫째로, loading을 제외하고, measurement_0 ~ 17을 입력으로 failure를 대상 변수로 Linear Discrimant Analysis(LDA) 모델을 만든다. \n",
    "\n",
    "True/False 이진 변수인 failure를 분류한다는 점에서 LDA 모델은 measurement_0 ~ 17를 한 개의 경계점으로 \n",
    "\n",
    "failure를 최대한 정확하게 구분하도록 하나의 연속형 변수로 변환한다. \n",
    "\n",
    "스프링의 내구력이 높을 수록 failure 확률이 낮아진다면, \n",
    "\n",
    "측정값 measurement_0 ~ 17의 LDA 변환값은 스프링의 내구력을 나타낸다라고 할 수 있다.\n",
    "\n",
    "실험에서 스프링에 가한 부하(loading)와  LDA 변환값의 상관도를 측정하여, \n",
    "\n",
    "측정값 measurement_0~17 에서 예상되는 내구력이 스프링에 따라 부하(loading)의 반영 정도를 가늠한다.\n",
    "\n",
    "둘째로, PCA를 사용하여 차원 감소로 failure 분류 성능에 얼마나 효과가 있을지 살펴본다.\n",
    "\n",
    "문제3에서 사용했던, 전처리(loading 결측치 처리와 표준화 과정을 거친) 과정을 거친 prob3_train과 prob3_test를 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee8e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3579a749",
   "metadata": {},
   "source": [
    "## 단계 4-1\n",
    "\n",
    "prob3_train에서 measurement_0 ~ 17을 입력으로 failure를 대상 변수로 하여 LDA(Linear Discriminant Analysis) 모델을 학습한다. \n",
    "\n",
    "measurement_0 ~ 17에 대한 prob3_train에서의 LDA의 변환값과 loading과 스피어만 상관도 (spearman correlation)의 p-value를 구하여 A라고 한다.\n",
    "\n",
    "입력 변수] measurement_0 ~ 17 (순서에 유의 하시오)\n",
    "\n",
    "대상 변수] failure\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.discriminant_analysis 제공 기능 활용\n",
    "\n",
    "scipy.stats.spearmanr\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6bbc9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=0.0029462997112993335, pvalue=0.6995009550811424),\n",
       " 0.6995009550811424)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_lda = ['measurement_{}'.format(i) for i in range(18)]\n",
    "lda.fit(df_prob3_train[X_lda], df_prob3_train['failure'])\n",
    "# LDA는 predict label 예측 기능을 제공합니다. \n",
    "# transform은 변환값을 가져옵니다.\n",
    "lda.transform(df_prob3_train[X_lda])[:, 0]\n",
    "result = spearmanr(lda.transform(df_prob3_train[X_lda])[:, 0], df_prob3_train['loading'])\n",
    "A = result.pvalue\n",
    "result, A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e726a4a",
   "metadata": {},
   "source": [
    "## 단계 4-2\n",
    "\n",
    "prob3_train에서 measurement_0 ~ 17을 대상으로 주성분분석(Principal Component Analysis, PCA) 모델을 학습한다. \n",
    "\n",
    "분산 설명율이 높은 순으로 주성분을 변수명을 pca_0 ~ 17하여 prob3_train에 추가하여 prob4_train을 만든다. \n",
    "\n",
    "prob3_test에 prob3_train를 학습했던 PCA 모델로 동일한 방법으로 pca0 ~17 파생 변수를 추가하여 prob4_test를 만든다.\n",
    "\n",
    "입력 변수] measurement_0 ~ 17 (순서에 유의 하시오)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.decomposition.PCA, random_state=123\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2934c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# pca.explained_variance_: Cov Matrix의 고윳값(eigen value)\n",
    "# pca.components_: 고유벡터(eigen value.T)\n",
    "# n_components를 지정을 하지 않으면, 모든 성분을 가져옵니다.\n",
    "pca = PCA(random_state=123)\n",
    "X_pca = ['measurement_{}'.format(i) for i in range(18)]\n",
    "df_prob4_train = df_prob3_train.copy()\n",
    "X_comp = ['pca{}'.format(i) for i in range(18)]\n",
    "\n",
    "# 시험장 버젼의 pandas는 numpy array된 여러개의 파생변수를 생성하지 못합니다.\n",
    "# pca에서 transform은 2-차원 numpy array인데요, 복수개의 컬럼을 추가하려면\n",
    "# 아래와 같이 DataFrame으로 만들어주어야 합니다. \n",
    "# 이 때 인덱스를 추가하려는 데이터프레임과 맞추어 주어야 의도한대로 추가가 됩니다. \n",
    "# 이 점 꼭 유의하세요!\n",
    "df_prob4_train[X_comp] = pd.DataFrame(\n",
    "    pca.fit_transform(df_prob3_train[X_pca]), \n",
    "    index=df_prob4_train.index,\n",
    "    columns=X_comp\n",
    ")\n",
    "df_prob4_test = df_prob3_test.copy()\n",
    "df_prob4_test[X_comp] = pd.DataFrame(\n",
    "    pca.transform(df_prob3_test[X_pca]), \n",
    "    index=df_prob4_test.index,\n",
    "    columns=X_comp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9e42879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob4_train[X_comp].isna().sum().sum(), df_prob4_test[X_comp].isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43a5fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고윳값(eigen_value), 고유행렬(eigen matrix)\n",
    "eval, evec = np.linalg.eig(df_prob4_train[X_pca].cov())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e65d434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.85613793, 1.41894459, 1.25547315, 1.1632852 , 1.06637856,\n",
       "        1.05000212, 1.01995967, 1.00922255, 1.00657757, 0.99213623,\n",
       "        0.98552903, 0.97614082, 0.97170312, 0.87532548, 0.81399432,\n",
       "        0.70771288, 0.67969009, 0.15283534]),\n",
       " array([1.85613793, 1.41894459, 1.25547315, 1.1632852 , 1.06637856,\n",
       "        1.05000212, 1.01995967, 1.00922255, 1.00657757, 0.99213623,\n",
       "        0.98552903, 0.97614082, 0.97170312, 0.87532548, 0.81399432,\n",
       "        0.70771288, 0.67969009, 0.15283534]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공분산행렬의 분산설명율 = 고윳값(eigen value)\n",
    "eval[np.argsort(-eval)], pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05c7269c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.02288252,  0.01958201,  0.01509695, -0.05039369, -0.20405996,\n",
       "         -0.3711166 , -0.19052884, -0.26894856, -0.42706392, -0.16470465,\n",
       "          0.00990499,  0.02259867, -0.00279912,  0.03389473, -0.01152647,\n",
       "          0.02018188,  0.02793587, -0.70407787],\n",
       "        [ 0.5265173 , -0.56246961, -0.10369017,  0.01685453, -0.04244735,\n",
       "          0.03673961,  0.00081529,  0.02135161, -0.05952021, -0.00180437,\n",
       "          0.00802201,  0.24569549,  0.38047553, -0.14457   , -0.11308728,\n",
       "         -0.38371312,  0.03955338, -0.02315167],\n",
       "        [ 0.18639051, -0.07481022, -0.14281368, -0.00388896, -0.05283629,\n",
       "         -0.00775108, -0.02935563,  0.01660702, -0.03187329,  0.02290234,\n",
       "          0.09287057, -0.36511369, -0.28604469, -0.29875793,  0.39673895,\n",
       "         -0.17077172, -0.65785228, -0.03709719]]),\n",
       " array([[ 0.02288252, -0.01958201, -0.01509695,  0.05039369,  0.20405996,\n",
       "          0.3711166 ,  0.19052884,  0.26894856,  0.42706392,  0.16470465,\n",
       "         -0.00990499, -0.02259867,  0.00279912, -0.03389473,  0.01152647,\n",
       "         -0.02018188, -0.02793587,  0.70407787],\n",
       "        [ 0.5265173 , -0.56246961, -0.10369017,  0.01685453, -0.04244735,\n",
       "          0.03673961,  0.00081529,  0.02135161, -0.05952021, -0.00180437,\n",
       "          0.00802201,  0.24569549,  0.38047553, -0.14457   , -0.11308728,\n",
       "         -0.38371312,  0.03955338, -0.02315167],\n",
       "        [-0.18639051,  0.07481022,  0.14281368,  0.00388896,  0.05283629,\n",
       "          0.00775108,  0.02935563, -0.01660702,  0.03187329, -0.02290234,\n",
       "         -0.09287057,  0.36511369,  0.28604469,  0.29875793, -0.39673895,\n",
       "          0.17077172,  0.65785228,  0.03709719]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공분산행렬의 고유행렬(eigen matrix)의 전치행렬\n",
    "# pca.components_는 svdflip이라는 후처리 과정이 있고 결과에 따라 부호가 바뀔수 있습니다.\n",
    "# 이를 고려하면 evec.T는 pca.components_라고 할 수 있습니다.\n",
    "evec.T[np.argsort(-eval)[:3]], pca.components_[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b97ba091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca0</th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "      <th>pca3</th>\n",
       "      <th>pca4</th>\n",
       "      <th>pca5</th>\n",
       "      <th>pca6</th>\n",
       "      <th>pca7</th>\n",
       "      <th>pca8</th>\n",
       "      <th>pca9</th>\n",
       "      <th>pca10</th>\n",
       "      <th>pca11</th>\n",
       "      <th>pca12</th>\n",
       "      <th>pca13</th>\n",
       "      <th>pca14</th>\n",
       "      <th>pca15</th>\n",
       "      <th>pca16</th>\n",
       "      <th>pca17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12186</td>\n",
       "      <td>2.960512</td>\n",
       "      <td>-1.489655</td>\n",
       "      <td>-0.582967</td>\n",
       "      <td>0.348241</td>\n",
       "      <td>2.542829</td>\n",
       "      <td>0.896912</td>\n",
       "      <td>1.334137</td>\n",
       "      <td>1.087665</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>-1.216006</td>\n",
       "      <td>-1.461594</td>\n",
       "      <td>1.366461</td>\n",
       "      <td>-0.286995</td>\n",
       "      <td>-0.736695</td>\n",
       "      <td>0.116673</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.163881</td>\n",
       "      <td>-0.465342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7532</td>\n",
       "      <td>-1.798466</td>\n",
       "      <td>-0.855238</td>\n",
       "      <td>1.671108</td>\n",
       "      <td>-1.163269</td>\n",
       "      <td>0.545993</td>\n",
       "      <td>-0.199374</td>\n",
       "      <td>-2.231717</td>\n",
       "      <td>0.103682</td>\n",
       "      <td>-0.125304</td>\n",
       "      <td>-1.003035</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>-1.036229</td>\n",
       "      <td>-0.147873</td>\n",
       "      <td>-0.587166</td>\n",
       "      <td>1.516481</td>\n",
       "      <td>0.656874</td>\n",
       "      <td>-1.360975</td>\n",
       "      <td>-0.366738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5469</td>\n",
       "      <td>1.729983</td>\n",
       "      <td>-1.543231</td>\n",
       "      <td>1.360306</td>\n",
       "      <td>-0.114138</td>\n",
       "      <td>0.495201</td>\n",
       "      <td>0.219880</td>\n",
       "      <td>-1.290541</td>\n",
       "      <td>0.577351</td>\n",
       "      <td>1.274128</td>\n",
       "      <td>-1.260589</td>\n",
       "      <td>0.142090</td>\n",
       "      <td>0.689487</td>\n",
       "      <td>1.260814</td>\n",
       "      <td>0.150481</td>\n",
       "      <td>-1.411919</td>\n",
       "      <td>0.530856</td>\n",
       "      <td>0.642580</td>\n",
       "      <td>-1.134623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5998</td>\n",
       "      <td>1.228829</td>\n",
       "      <td>-0.689356</td>\n",
       "      <td>0.904971</td>\n",
       "      <td>-0.227123</td>\n",
       "      <td>-0.393074</td>\n",
       "      <td>0.501715</td>\n",
       "      <td>0.574737</td>\n",
       "      <td>0.082809</td>\n",
       "      <td>0.516806</td>\n",
       "      <td>-0.783940</td>\n",
       "      <td>0.199165</td>\n",
       "      <td>2.100699</td>\n",
       "      <td>0.046940</td>\n",
       "      <td>0.309664</td>\n",
       "      <td>0.277571</td>\n",
       "      <td>1.093004</td>\n",
       "      <td>-1.001688</td>\n",
       "      <td>-0.209835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21825</td>\n",
       "      <td>0.642582</td>\n",
       "      <td>-1.894125</td>\n",
       "      <td>-3.405371</td>\n",
       "      <td>1.549242</td>\n",
       "      <td>0.147123</td>\n",
       "      <td>0.204921</td>\n",
       "      <td>-0.530752</td>\n",
       "      <td>-0.565281</td>\n",
       "      <td>-1.305984</td>\n",
       "      <td>0.337364</td>\n",
       "      <td>-2.846921</td>\n",
       "      <td>-0.310261</td>\n",
       "      <td>0.439548</td>\n",
       "      <td>1.036061</td>\n",
       "      <td>-3.057189</td>\n",
       "      <td>0.604486</td>\n",
       "      <td>-0.059815</td>\n",
       "      <td>-1.033242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pca0      pca1      pca2      pca3      pca4      pca5      pca6  \\\n",
       "id                                                                            \n",
       "12186  2.960512 -1.489655 -0.582967  0.348241  2.542829  0.896912  1.334137   \n",
       "7532  -1.798466 -0.855238  1.671108 -1.163269  0.545993 -0.199374 -2.231717   \n",
       "5469   1.729983 -1.543231  1.360306 -0.114138  0.495201  0.219880 -1.290541   \n",
       "5998   1.228829 -0.689356  0.904971 -0.227123 -0.393074  0.501715  0.574737   \n",
       "21825  0.642582 -1.894125 -3.405371  1.549242  0.147123  0.204921 -0.530752   \n",
       "\n",
       "           pca7      pca8      pca9     pca10     pca11     pca12     pca13  \\\n",
       "id                                                                            \n",
       "12186  1.087665  0.069564 -1.216006 -1.461594  1.366461 -0.286995 -0.736695   \n",
       "7532   0.103682 -0.125304 -1.003035 -0.529226 -1.036229 -0.147873 -0.587166   \n",
       "5469   0.577351  1.274128 -1.260589  0.142090  0.689487  1.260814  0.150481   \n",
       "5998   0.082809  0.516806 -0.783940  0.199165  2.100699  0.046940  0.309664   \n",
       "21825 -0.565281 -1.305984  0.337364 -2.846921 -0.310261  0.439548  1.036061   \n",
       "\n",
       "          pca14     pca15     pca16     pca17  \n",
       "id                                             \n",
       "12186  0.116673  0.194459  0.163881 -0.465342  \n",
       "7532   1.516481  0.656874 -1.360975 -0.366738  \n",
       "5469  -1.411919  0.530856  0.642580 -1.134623  \n",
       "5998   0.277571  1.093004 -1.001688 -0.209835  \n",
       "21825 -3.057189  0.604486 -0.059815 -1.033242  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform: 수동으로 변환: mean_centering한 입력값과 pca.components_.T와 행렬곱을 합니다.\n",
    "(df_prob4_train[X_pca] - df_prob4_train[X_pca].mean()).dot(pca.components_.T)\\\n",
    "        .rename(columns=lambda x: 'pca{}'.format(x)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35c06a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca0</th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "      <th>pca3</th>\n",
       "      <th>pca4</th>\n",
       "      <th>pca5</th>\n",
       "      <th>pca6</th>\n",
       "      <th>pca7</th>\n",
       "      <th>pca8</th>\n",
       "      <th>pca9</th>\n",
       "      <th>pca10</th>\n",
       "      <th>pca11</th>\n",
       "      <th>pca12</th>\n",
       "      <th>pca13</th>\n",
       "      <th>pca14</th>\n",
       "      <th>pca15</th>\n",
       "      <th>pca16</th>\n",
       "      <th>pca17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12186</td>\n",
       "      <td>2.960512</td>\n",
       "      <td>-1.489655</td>\n",
       "      <td>-0.582967</td>\n",
       "      <td>0.348241</td>\n",
       "      <td>2.542829</td>\n",
       "      <td>0.896912</td>\n",
       "      <td>1.334137</td>\n",
       "      <td>1.087665</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>-1.216006</td>\n",
       "      <td>-1.461594</td>\n",
       "      <td>1.366461</td>\n",
       "      <td>-0.286995</td>\n",
       "      <td>-0.736695</td>\n",
       "      <td>0.116673</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.163881</td>\n",
       "      <td>-0.465342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7532</td>\n",
       "      <td>-1.798466</td>\n",
       "      <td>-0.855238</td>\n",
       "      <td>1.671108</td>\n",
       "      <td>-1.163269</td>\n",
       "      <td>0.545993</td>\n",
       "      <td>-0.199374</td>\n",
       "      <td>-2.231717</td>\n",
       "      <td>0.103682</td>\n",
       "      <td>-0.125304</td>\n",
       "      <td>-1.003035</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>-1.036229</td>\n",
       "      <td>-0.147873</td>\n",
       "      <td>-0.587166</td>\n",
       "      <td>1.516481</td>\n",
       "      <td>0.656874</td>\n",
       "      <td>-1.360975</td>\n",
       "      <td>-0.366738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5469</td>\n",
       "      <td>1.729983</td>\n",
       "      <td>-1.543231</td>\n",
       "      <td>1.360306</td>\n",
       "      <td>-0.114138</td>\n",
       "      <td>0.495201</td>\n",
       "      <td>0.219880</td>\n",
       "      <td>-1.290541</td>\n",
       "      <td>0.577351</td>\n",
       "      <td>1.274128</td>\n",
       "      <td>-1.260589</td>\n",
       "      <td>0.142090</td>\n",
       "      <td>0.689487</td>\n",
       "      <td>1.260814</td>\n",
       "      <td>0.150481</td>\n",
       "      <td>-1.411919</td>\n",
       "      <td>0.530856</td>\n",
       "      <td>0.642580</td>\n",
       "      <td>-1.134623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5998</td>\n",
       "      <td>1.228829</td>\n",
       "      <td>-0.689356</td>\n",
       "      <td>0.904971</td>\n",
       "      <td>-0.227123</td>\n",
       "      <td>-0.393074</td>\n",
       "      <td>0.501715</td>\n",
       "      <td>0.574737</td>\n",
       "      <td>0.082809</td>\n",
       "      <td>0.516806</td>\n",
       "      <td>-0.783940</td>\n",
       "      <td>0.199165</td>\n",
       "      <td>2.100699</td>\n",
       "      <td>0.046940</td>\n",
       "      <td>0.309664</td>\n",
       "      <td>0.277571</td>\n",
       "      <td>1.093004</td>\n",
       "      <td>-1.001688</td>\n",
       "      <td>-0.209835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21825</td>\n",
       "      <td>0.642582</td>\n",
       "      <td>-1.894125</td>\n",
       "      <td>-3.405371</td>\n",
       "      <td>1.549242</td>\n",
       "      <td>0.147123</td>\n",
       "      <td>0.204921</td>\n",
       "      <td>-0.530752</td>\n",
       "      <td>-0.565281</td>\n",
       "      <td>-1.305984</td>\n",
       "      <td>0.337364</td>\n",
       "      <td>-2.846921</td>\n",
       "      <td>-0.310261</td>\n",
       "      <td>0.439548</td>\n",
       "      <td>1.036061</td>\n",
       "      <td>-3.057189</td>\n",
       "      <td>0.604486</td>\n",
       "      <td>-0.059815</td>\n",
       "      <td>-1.033242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pca0      pca1      pca2      pca3      pca4      pca5      pca6  \\\n",
       "id                                                                            \n",
       "12186  2.960512 -1.489655 -0.582967  0.348241  2.542829  0.896912  1.334137   \n",
       "7532  -1.798466 -0.855238  1.671108 -1.163269  0.545993 -0.199374 -2.231717   \n",
       "5469   1.729983 -1.543231  1.360306 -0.114138  0.495201  0.219880 -1.290541   \n",
       "5998   1.228829 -0.689356  0.904971 -0.227123 -0.393074  0.501715  0.574737   \n",
       "21825  0.642582 -1.894125 -3.405371  1.549242  0.147123  0.204921 -0.530752   \n",
       "\n",
       "           pca7      pca8      pca9     pca10     pca11     pca12     pca13  \\\n",
       "id                                                                            \n",
       "12186  1.087665  0.069564 -1.216006 -1.461594  1.366461 -0.286995 -0.736695   \n",
       "7532   0.103682 -0.125304 -1.003035 -0.529226 -1.036229 -0.147873 -0.587166   \n",
       "5469   0.577351  1.274128 -1.260589  0.142090  0.689487  1.260814  0.150481   \n",
       "5998   0.082809  0.516806 -0.783940  0.199165  2.100699  0.046940  0.309664   \n",
       "21825 -0.565281 -1.305984  0.337364 -2.846921 -0.310261  0.439548  1.036061   \n",
       "\n",
       "          pca14     pca15     pca16     pca17  \n",
       "id                                             \n",
       "12186  0.116673  0.194459  0.163881 -0.465342  \n",
       "7532   1.516481  0.656874 -1.360975 -0.366738  \n",
       "5469  -1.411919  0.530856  0.642580 -1.134623  \n",
       "5998   0.277571  1.093004 -1.001688 -0.209835  \n",
       "21825 -3.057189  0.604486 -0.059815 -1.033242  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob4_train[X_comp].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99926f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>measurement_4</th>\n",
       "      <th>measurement_5</th>\n",
       "      <th>measurement_6</th>\n",
       "      <th>measurement_7</th>\n",
       "      <th>measurement_8</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12186</td>\n",
       "      <td>-1.014834</td>\n",
       "      <td>0.988654</td>\n",
       "      <td>0.608313</td>\n",
       "      <td>-1.219573</td>\n",
       "      <td>2.315742</td>\n",
       "      <td>2.149935</td>\n",
       "      <td>0.129206</td>\n",
       "      <td>0.481958</td>\n",
       "      <td>0.100301</td>\n",
       "      <td>1.853256</td>\n",
       "      <td>-1.409439</td>\n",
       "      <td>-0.944188</td>\n",
       "      <td>0.578288</td>\n",
       "      <td>0.269921</td>\n",
       "      <td>1.985320</td>\n",
       "      <td>-0.127064</td>\n",
       "      <td>-0.473798</td>\n",
       "      <td>1.753419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7532</td>\n",
       "      <td>-1.250324</td>\n",
       "      <td>-0.929650</td>\n",
       "      <td>0.912362</td>\n",
       "      <td>-1.220579</td>\n",
       "      <td>-1.797575</td>\n",
       "      <td>-0.771911</td>\n",
       "      <td>0.175545</td>\n",
       "      <td>-0.629557</td>\n",
       "      <td>0.212792</td>\n",
       "      <td>0.434345</td>\n",
       "      <td>-0.112895</td>\n",
       "      <td>-0.632997</td>\n",
       "      <td>0.535767</td>\n",
       "      <td>-0.365820</td>\n",
       "      <td>-0.065802</td>\n",
       "      <td>2.202253</td>\n",
       "      <td>1.973899</td>\n",
       "      <td>-1.441619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5469</td>\n",
       "      <td>-0.779343</td>\n",
       "      <td>0.748866</td>\n",
       "      <td>1.824512</td>\n",
       "      <td>-1.582543</td>\n",
       "      <td>1.189823</td>\n",
       "      <td>0.945189</td>\n",
       "      <td>1.470030</td>\n",
       "      <td>0.086709</td>\n",
       "      <td>1.522865</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>0.221063</td>\n",
       "      <td>1.196195</td>\n",
       "      <td>-1.241071</td>\n",
       "      <td>0.600403</td>\n",
       "      <td>0.533841</td>\n",
       "      <td>0.247869</td>\n",
       "      <td>0.994222</td>\n",
       "      <td>0.554850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5998</td>\n",
       "      <td>-1.485815</td>\n",
       "      <td>-0.210286</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>-0.999378</td>\n",
       "      <td>1.477825</td>\n",
       "      <td>0.381844</td>\n",
       "      <td>1.196022</td>\n",
       "      <td>0.375622</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>0.004035</td>\n",
       "      <td>0.034832</td>\n",
       "      <td>-1.013130</td>\n",
       "      <td>-0.136908</td>\n",
       "      <td>0.695199</td>\n",
       "      <td>-0.648998</td>\n",
       "      <td>-0.889767</td>\n",
       "      <td>0.923604</td>\n",
       "      <td>0.776436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21825</td>\n",
       "      <td>-1.014834</td>\n",
       "      <td>0.988654</td>\n",
       "      <td>-0.607887</td>\n",
       "      <td>-0.353874</td>\n",
       "      <td>-0.441856</td>\n",
       "      <td>0.508145</td>\n",
       "      <td>-0.994024</td>\n",
       "      <td>2.443161</td>\n",
       "      <td>-0.166492</td>\n",
       "      <td>2.019535</td>\n",
       "      <td>-0.195440</td>\n",
       "      <td>1.137372</td>\n",
       "      <td>-3.613207</td>\n",
       "      <td>-0.893721</td>\n",
       "      <td>2.367721</td>\n",
       "      <td>-0.937056</td>\n",
       "      <td>-2.220102</td>\n",
       "      <td>-0.338670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       measurement_0  measurement_1  measurement_2  measurement_3  \\\n",
       "id                                                                  \n",
       "12186      -1.014834       0.988654       0.608313      -1.219573   \n",
       "7532       -1.250324      -0.929650       0.912362      -1.220579   \n",
       "5469       -0.779343       0.748866       1.824512      -1.582543   \n",
       "5998       -1.485815      -0.210286       0.000213      -0.999378   \n",
       "21825      -1.014834       0.988654      -0.607887      -0.353874   \n",
       "\n",
       "       measurement_4  measurement_5  measurement_6  measurement_7  \\\n",
       "id                                                                  \n",
       "12186       2.315742       2.149935       0.129206       0.481958   \n",
       "7532       -1.797575      -0.771911       0.175545      -0.629557   \n",
       "5469        1.189823       0.945189       1.470030       0.086709   \n",
       "5998        1.477825       0.381844       1.196022       0.375622   \n",
       "21825      -0.441856       0.508145      -0.994024       2.443161   \n",
       "\n",
       "       measurement_8  measurement_9  measurement_10  measurement_11  \\\n",
       "id                                                                    \n",
       "12186       0.100301       1.853256       -1.409439       -0.944188   \n",
       "7532        0.212792       0.434345       -0.112895       -0.632997   \n",
       "5469        1.522865       0.069539        0.221063        1.196195   \n",
       "5998        0.014725       0.004035        0.034832       -1.013130   \n",
       "21825      -0.166492       2.019535       -0.195440        1.137372   \n",
       "\n",
       "       measurement_12  measurement_13  measurement_14  measurement_15  \\\n",
       "id                                                                      \n",
       "12186        0.578288        0.269921        1.985320       -0.127064   \n",
       "7532         0.535767       -0.365820       -0.065802        2.202253   \n",
       "5469        -1.241071        0.600403        0.533841        0.247869   \n",
       "5998        -0.136908        0.695199       -0.648998       -0.889767   \n",
       "21825       -3.613207       -0.893721        2.367721       -0.937056   \n",
       "\n",
       "       measurement_16  measurement_17  \n",
       "id                                     \n",
       "12186       -0.473798        1.753419  \n",
       "7532         1.973899       -1.441619  \n",
       "5469         0.994222        0.554850  \n",
       "5998         0.923604        0.776436  \n",
       "21825       -2.220102       -0.338670  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inverse_transform: pca 역변환, PCA 변환값에서 원래값으로 \n",
    "# 모든 PCA성분으로 하면 원래값으로 정확히 돌아갑니다. \n",
    "# PCA 성분수를 줄일 수록 역변환 했을 때 오차가 커집니다.\n",
    "pd.DataFrame(\n",
    "    pca.inverse_transform(df_prob4_train[X_comp]), \n",
    "    index = df_prob4_train.index, columns=X_pca\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7eb41710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>measurement_4</th>\n",
       "      <th>measurement_5</th>\n",
       "      <th>measurement_6</th>\n",
       "      <th>measurement_7</th>\n",
       "      <th>measurement_8</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12186</td>\n",
       "      <td>-1.014834</td>\n",
       "      <td>0.988654</td>\n",
       "      <td>0.608313</td>\n",
       "      <td>-1.219573</td>\n",
       "      <td>2.315742</td>\n",
       "      <td>2.149935</td>\n",
       "      <td>0.129206</td>\n",
       "      <td>0.481958</td>\n",
       "      <td>0.100301</td>\n",
       "      <td>1.853256</td>\n",
       "      <td>-1.409439</td>\n",
       "      <td>-0.944188</td>\n",
       "      <td>0.578288</td>\n",
       "      <td>0.269921</td>\n",
       "      <td>1.985320</td>\n",
       "      <td>-0.127064</td>\n",
       "      <td>-0.473798</td>\n",
       "      <td>1.753419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7532</td>\n",
       "      <td>-1.250324</td>\n",
       "      <td>-0.929650</td>\n",
       "      <td>0.912362</td>\n",
       "      <td>-1.220579</td>\n",
       "      <td>-1.797575</td>\n",
       "      <td>-0.771911</td>\n",
       "      <td>0.175545</td>\n",
       "      <td>-0.629557</td>\n",
       "      <td>0.212792</td>\n",
       "      <td>0.434345</td>\n",
       "      <td>-0.112895</td>\n",
       "      <td>-0.632997</td>\n",
       "      <td>0.535767</td>\n",
       "      <td>-0.365820</td>\n",
       "      <td>-0.065802</td>\n",
       "      <td>2.202253</td>\n",
       "      <td>1.973899</td>\n",
       "      <td>-1.441619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5469</td>\n",
       "      <td>-0.779343</td>\n",
       "      <td>0.748866</td>\n",
       "      <td>1.824512</td>\n",
       "      <td>-1.582543</td>\n",
       "      <td>1.189823</td>\n",
       "      <td>0.945189</td>\n",
       "      <td>1.470030</td>\n",
       "      <td>0.086709</td>\n",
       "      <td>1.522865</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>0.221063</td>\n",
       "      <td>1.196195</td>\n",
       "      <td>-1.241071</td>\n",
       "      <td>0.600403</td>\n",
       "      <td>0.533841</td>\n",
       "      <td>0.247869</td>\n",
       "      <td>0.994222</td>\n",
       "      <td>0.554850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5998</td>\n",
       "      <td>-1.485815</td>\n",
       "      <td>-0.210286</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>-0.999378</td>\n",
       "      <td>1.477825</td>\n",
       "      <td>0.381844</td>\n",
       "      <td>1.196022</td>\n",
       "      <td>0.375622</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>0.004035</td>\n",
       "      <td>0.034832</td>\n",
       "      <td>-1.013130</td>\n",
       "      <td>-0.136908</td>\n",
       "      <td>0.695199</td>\n",
       "      <td>-0.648998</td>\n",
       "      <td>-0.889767</td>\n",
       "      <td>0.923604</td>\n",
       "      <td>0.776436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21825</td>\n",
       "      <td>-1.014834</td>\n",
       "      <td>0.988654</td>\n",
       "      <td>-0.607887</td>\n",
       "      <td>-0.353874</td>\n",
       "      <td>-0.441856</td>\n",
       "      <td>0.508145</td>\n",
       "      <td>-0.994024</td>\n",
       "      <td>2.443161</td>\n",
       "      <td>-0.166492</td>\n",
       "      <td>2.019535</td>\n",
       "      <td>-0.195440</td>\n",
       "      <td>1.137372</td>\n",
       "      <td>-3.613207</td>\n",
       "      <td>-0.893721</td>\n",
       "      <td>2.367721</td>\n",
       "      <td>-0.937056</td>\n",
       "      <td>-2.220102</td>\n",
       "      <td>-0.338670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       measurement_0  measurement_1  measurement_2  measurement_3  \\\n",
       "id                                                                  \n",
       "12186      -1.014834       0.988654       0.608313      -1.219573   \n",
       "7532       -1.250324      -0.929650       0.912362      -1.220579   \n",
       "5469       -0.779343       0.748866       1.824512      -1.582543   \n",
       "5998       -1.485815      -0.210286       0.000213      -0.999378   \n",
       "21825      -1.014834       0.988654      -0.607887      -0.353874   \n",
       "\n",
       "       measurement_4  measurement_5  measurement_6  measurement_7  \\\n",
       "id                                                                  \n",
       "12186       2.315742       2.149935       0.129206       0.481958   \n",
       "7532       -1.797575      -0.771911       0.175545      -0.629557   \n",
       "5469        1.189823       0.945189       1.470030       0.086709   \n",
       "5998        1.477825       0.381844       1.196022       0.375622   \n",
       "21825      -0.441856       0.508145      -0.994024       2.443161   \n",
       "\n",
       "       measurement_8  measurement_9  measurement_10  measurement_11  \\\n",
       "id                                                                    \n",
       "12186       0.100301       1.853256       -1.409439       -0.944188   \n",
       "7532        0.212792       0.434345       -0.112895       -0.632997   \n",
       "5469        1.522865       0.069539        0.221063        1.196195   \n",
       "5998        0.014725       0.004035        0.034832       -1.013130   \n",
       "21825      -0.166492       2.019535       -0.195440        1.137372   \n",
       "\n",
       "       measurement_12  measurement_13  measurement_14  measurement_15  \\\n",
       "id                                                                      \n",
       "12186        0.578288        0.269921        1.985320       -0.127064   \n",
       "7532         0.535767       -0.365820       -0.065802        2.202253   \n",
       "5469        -1.241071        0.600403        0.533841        0.247869   \n",
       "5998        -0.136908        0.695199       -0.648998       -0.889767   \n",
       "21825       -3.613207       -0.893721        2.367721       -0.937056   \n",
       "\n",
       "       measurement_16  measurement_17  \n",
       "id                                     \n",
       "12186       -0.473798        1.753419  \n",
       "7532         1.973899       -1.441619  \n",
       "5469         0.994222        0.554850  \n",
       "5998         0.923604        0.776436  \n",
       "21825       -2.220102       -0.338670  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inverse_transform을 직접해봅니다.\n",
    "(\n",
    "    (df_prob4_train[X_comp]).dot(pca.components_).rename(columns=lambda x: 'measurement_{}'.format(x))\\\n",
    "        + df_prob4_train[X_pca].mean()\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee73ced8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>measurement_4</th>\n",
       "      <th>measurement_5</th>\n",
       "      <th>measurement_6</th>\n",
       "      <th>measurement_7</th>\n",
       "      <th>measurement_8</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12186</td>\n",
       "      <td>-1.014834</td>\n",
       "      <td>0.988654</td>\n",
       "      <td>0.608313</td>\n",
       "      <td>-1.219573</td>\n",
       "      <td>2.315742</td>\n",
       "      <td>2.149935</td>\n",
       "      <td>0.129206</td>\n",
       "      <td>0.481958</td>\n",
       "      <td>0.100301</td>\n",
       "      <td>1.853256</td>\n",
       "      <td>-1.409439</td>\n",
       "      <td>-0.944188</td>\n",
       "      <td>0.578288</td>\n",
       "      <td>0.269921</td>\n",
       "      <td>1.985320</td>\n",
       "      <td>-0.127064</td>\n",
       "      <td>-0.473798</td>\n",
       "      <td>1.753419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7532</td>\n",
       "      <td>-1.250324</td>\n",
       "      <td>-0.929650</td>\n",
       "      <td>0.912362</td>\n",
       "      <td>-1.220579</td>\n",
       "      <td>-1.797575</td>\n",
       "      <td>-0.771911</td>\n",
       "      <td>0.175545</td>\n",
       "      <td>-0.629557</td>\n",
       "      <td>0.212792</td>\n",
       "      <td>0.434345</td>\n",
       "      <td>-0.112895</td>\n",
       "      <td>-0.632997</td>\n",
       "      <td>0.535767</td>\n",
       "      <td>-0.365820</td>\n",
       "      <td>-0.065802</td>\n",
       "      <td>2.202253</td>\n",
       "      <td>1.973899</td>\n",
       "      <td>-1.441619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5469</td>\n",
       "      <td>-0.779343</td>\n",
       "      <td>0.748866</td>\n",
       "      <td>1.824512</td>\n",
       "      <td>-1.582543</td>\n",
       "      <td>1.189823</td>\n",
       "      <td>0.945189</td>\n",
       "      <td>1.470030</td>\n",
       "      <td>0.086709</td>\n",
       "      <td>1.522865</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>0.221063</td>\n",
       "      <td>1.196195</td>\n",
       "      <td>-1.241071</td>\n",
       "      <td>0.600403</td>\n",
       "      <td>0.533841</td>\n",
       "      <td>0.247869</td>\n",
       "      <td>0.994222</td>\n",
       "      <td>0.554850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5998</td>\n",
       "      <td>-1.485815</td>\n",
       "      <td>-0.210286</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>-0.999378</td>\n",
       "      <td>1.477825</td>\n",
       "      <td>0.381844</td>\n",
       "      <td>1.196022</td>\n",
       "      <td>0.375622</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>0.004035</td>\n",
       "      <td>0.034832</td>\n",
       "      <td>-1.013130</td>\n",
       "      <td>-0.136908</td>\n",
       "      <td>0.695199</td>\n",
       "      <td>-0.648998</td>\n",
       "      <td>-0.889767</td>\n",
       "      <td>0.923604</td>\n",
       "      <td>0.776436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21825</td>\n",
       "      <td>-1.014834</td>\n",
       "      <td>0.988654</td>\n",
       "      <td>-0.607887</td>\n",
       "      <td>-0.353874</td>\n",
       "      <td>-0.441856</td>\n",
       "      <td>0.508145</td>\n",
       "      <td>-0.994024</td>\n",
       "      <td>2.443161</td>\n",
       "      <td>-0.166492</td>\n",
       "      <td>2.019535</td>\n",
       "      <td>-0.195440</td>\n",
       "      <td>1.137372</td>\n",
       "      <td>-3.613207</td>\n",
       "      <td>-0.893721</td>\n",
       "      <td>2.367721</td>\n",
       "      <td>-0.937056</td>\n",
       "      <td>-2.220102</td>\n",
       "      <td>-0.338670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       measurement_0  measurement_1  measurement_2  measurement_3  \\\n",
       "id                                                                  \n",
       "12186      -1.014834       0.988654       0.608313      -1.219573   \n",
       "7532       -1.250324      -0.929650       0.912362      -1.220579   \n",
       "5469       -0.779343       0.748866       1.824512      -1.582543   \n",
       "5998       -1.485815      -0.210286       0.000213      -0.999378   \n",
       "21825      -1.014834       0.988654      -0.607887      -0.353874   \n",
       "\n",
       "       measurement_4  measurement_5  measurement_6  measurement_7  \\\n",
       "id                                                                  \n",
       "12186       2.315742       2.149935       0.129206       0.481958   \n",
       "7532       -1.797575      -0.771911       0.175545      -0.629557   \n",
       "5469        1.189823       0.945189       1.470030       0.086709   \n",
       "5998        1.477825       0.381844       1.196022       0.375622   \n",
       "21825      -0.441856       0.508145      -0.994024       2.443161   \n",
       "\n",
       "       measurement_8  measurement_9  measurement_10  measurement_11  \\\n",
       "id                                                                    \n",
       "12186       0.100301       1.853256       -1.409439       -0.944188   \n",
       "7532        0.212792       0.434345       -0.112895       -0.632997   \n",
       "5469        1.522865       0.069539        0.221063        1.196195   \n",
       "5998        0.014725       0.004035        0.034832       -1.013130   \n",
       "21825      -0.166492       2.019535       -0.195440        1.137372   \n",
       "\n",
       "       measurement_12  measurement_13  measurement_14  measurement_15  \\\n",
       "id                                                                      \n",
       "12186        0.578288        0.269921        1.985320       -0.127064   \n",
       "7532         0.535767       -0.365820       -0.065802        2.202253   \n",
       "5469        -1.241071        0.600403        0.533841        0.247869   \n",
       "5998        -0.136908        0.695199       -0.648998       -0.889767   \n",
       "21825       -3.613207       -0.893721        2.367721       -0.937056   \n",
       "\n",
       "       measurement_16  measurement_17  \n",
       "id                                     \n",
       "12186       -0.473798        1.753419  \n",
       "7532         1.973899       -1.441619  \n",
       "5469         0.994222        0.554850  \n",
       "5998         0.923604        0.776436  \n",
       "21825       -2.220102       -0.338670  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원래값과 비교해봅니다.\n",
    "df_prob4_train[X_pca].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d71204",
   "metadata": {},
   "source": [
    "## 단계 4-3\n",
    "\n",
    "초기에 loading을 입력 변수로 하여 prob4_train을 학습하고, prob4_test에 대한 성능을 측정한다.\n",
    "\n",
    "여기에 pca_0에서 pca_17까지 입력 변수를 하나씩 추가 하면서, \n",
    "\n",
    "즉 분산 설명율이 높은 순으로 컴포넌트를 하나씩 추가하여 prob4_train를 학습하고 prob4_test의 성능을 측정 했을 때, \n",
    "\n",
    "최적의 성능을 보인 컴포넌트들의 분산 설명율의 합을 B라고 한다. (만일 없다면 B = 0이다.)\n",
    "\n",
    "입력 변수: 설명 참고\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC(area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.linear_model.LogisticRegression, solver=’lbfgs’\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8afec2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 0.5886355699157924 0.5778277926972065\n",
      "pca0 0.5902607636650189 0.579565141627812\n",
      "pca1 0.5906173884232395 0.5784170060859327\n",
      "pca2 0.5906803365700851 0.5786498903164131\n",
      "pca3 0.5911363799178113 0.5801256923420173\n",
      "pca4 0.5912654510937876 0.5805735466314028\n",
      "pca5 0.5914601161518473 0.5811103203542446\n",
      "pca6 0.5929702204182378 0.581757510516433\n",
      "pca7 0.5934465748718649 0.5808025223153578\n",
      "pca8 0.5935233418973748 0.5801787834323228\n",
      "pca9 0.593551407042703 0.5801664063683251\n",
      "pca10 0.5937232780741002 0.5794231311040503\n",
      "pca11 0.5940223479149978 0.5785678108393766\n",
      "pca12 0.594022551433093 0.5782202759108135\n",
      "pca13 0.593998210668907 0.5782310244137587\n",
      "pca14 0.5938648656129314 0.5776818736269195\n",
      "pca15 0.5941303346163114 0.5772988360674158\n",
      "pca16 0.5941881134035389 0.5768773644670778\n",
      "pca17 0.5945461424366163 0.5771252314592396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_values = ['loading'] + ['pca{}'.format(i) for i in range(18)]\n",
    "scores, scores_train = list(), list()\n",
    "X_lr = []\n",
    "clf_lr = LogisticRegression(solver='lbfgs')\n",
    "for i in X_values:\n",
    "    X_lr.append(i)\n",
    "    clf_lr.fit(df_prob4_train[X_lr], df_prob4_train['failure'])\n",
    "    scores_train.append(\n",
    "        roc_auc_score(df_prob4_train['failure'], clf_lr.predict_proba(df_prob4_train[X_lr])[:, 1])\n",
    "    )\n",
    "    scores.append(\n",
    "        roc_auc_score(df_prob4_test['failure'], clf_lr.predict_proba(df_prob4_test[X_lr])[:, 1])\n",
    "    )\n",
    "    print(i, scores_train[-1], scores[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c19ae14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4905370453061068, 7)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_comp = np.argmax(scores[1:]) + 1\n",
    "n_comp\n",
    "B = np.sum(pca.explained_variance_ratio_[:n_comp])\n",
    "B, n_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd01e87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10311277, 0.07882566, 0.06974445, 0.06462319, 0.0592398 ,\n",
       "       0.05833005, 0.05666113])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_[:n_comp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "423e0b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6995009550811424, 0.4905370453061068, 1.1900380003872493)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, B, A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a7e38",
   "metadata": {},
   "source": [
    "A + B를 소수점 셋째 자리에서 반올림하여 둘째 자리까지 구하라.\n",
    "\n",
    "**1.19**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ba3524",
   "metadata": {},
   "source": [
    "# 문제 5\n",
    "\n",
    "랜덤포레스트 분류기(Random-Forest Classifier)의 최적의 하이퍼 파라미터(Hyper-Parameter, 초매개변수)를 탐색하고자 한다.\n",
    "\n",
    "문제3에서 사용했던, 전처리(loading 결측치 처리와 표준화 과정을 거친) 과정을 거친 prob3_train과 prob3_test를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e99809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05189b7d",
   "metadata": {},
   "source": [
    "## 단계 5-1\n",
    "\n",
    "sklearn에서 제공하는 랜덤포레스트 분류기(Random-Forest Classifier)의 하이퍼 파라미터 중 \n",
    "\n",
    "n_estimators, max_depth 그리고 min_samples_split의 최적 조합을 탐색한다. \n",
    "\n",
    "탐색 값은 아래에 제공한 하이퍼 파라미터의 모든 조합이다. \n",
    "\n",
    "prob3_train을 대상으로 5-겹 층화교차검증(5-fold stratified cross validation)으로 \n",
    "\n",
    "각각 층의 겹외셋(OOF set, Out-Of-Fold set)의 성능에 대한 평균을 기준으로 하이퍼 파라미터를 선택한다.\n",
    "\n",
    "  - n_estimators: [5, 10, 15]\n",
    "\n",
    "  - max_depth: [5, 6, 7]\n",
    "  \n",
    "  - min_samples_split: [256, 512]\n",
    "\n",
    "Hint] 모든 하이퍼 파라미터의 조합의 수는 18개이다\n",
    "\n",
    "입력 변수: loading, measurement_0 ~ 17, na_1, na_2 (순서에 유의)\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC (area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.ensemble.RandomForestClassifier, random_state=123 \n",
    "\n",
    "itertools.product 필요시 사용\n",
    "\n",
    "sklearn.model_selection.cross_val_score 필요시 사용\n",
    "\n",
    "sklearn.model_selection.StratifiedKFold, random_state=123, shuffle=True\n",
    "\n",
    "sklearn.model_selection.GridSearchCV 필요시 사용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6226741f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False, random_state=123,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid=False, n_jobs=None,\n",
       "             param_grid={'max_depth': [5, 6, 7],\n",
       "                         'min_samples_split': [256, 512],\n",
       "                         'n_estimators': [5, 10, 15]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1: GridSearchCV를 이용합니다.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gscv = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=123), # 랜덤포레스트 분류기(Random-Forest Classifier)\n",
    "    cv=StratifiedKFold(5, random_state=123, shuffle=True), # 5-겹 층화교차검증(5-fold stratified cross validation\n",
    "    iid=False, # 각각 층의 겹외셋(OOF set, Out-Of-Fold set)의 성능에 대한 평균\n",
    "    param_grid = {\n",
    "        'n_estimators': [5, 10, 15],\n",
    "        'max_depth': [5, 6, 7],\n",
    "        'min_samples_split': [256, 512]\n",
    "    },\n",
    "    scoring='roc_auc' # 성능 지표: AUC (area under of ROC curve)\n",
    ")\n",
    "X_gscv = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "gscv.fit(df_prob3_train[X_gscv], df_prob3_train['failure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f50a652a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 7, 'min_samples_split': 512, 'n_estimators': 15},\n",
       " 0.5745226991354744)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_params_, gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a57fb698",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "36b7b378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'max_depth': 5, 'min_samples_split': 256} 0.5547115468443294\n",
      "{'n_estimators': 5, 'max_depth': 5, 'min_samples_split': 512} 0.5617150416141751\n",
      "{'n_estimators': 5, 'max_depth': 6, 'min_samples_split': 256} 0.5568999583940097\n",
      "{'n_estimators': 5, 'max_depth': 6, 'min_samples_split': 512} 0.5623239919998733\n",
      "{'n_estimators': 5, 'max_depth': 7, 'min_samples_split': 256} 0.5567633668997499\n",
      "{'n_estimators': 5, 'max_depth': 7, 'min_samples_split': 512} 0.5642015275666604\n",
      "{'n_estimators': 10, 'max_depth': 5, 'min_samples_split': 256} 0.5654552370913933\n",
      "{'n_estimators': 10, 'max_depth': 5, 'min_samples_split': 512} 0.5707474621000601\n",
      "{'n_estimators': 10, 'max_depth': 6, 'min_samples_split': 256} 0.5681316681217556\n",
      "{'n_estimators': 10, 'max_depth': 6, 'min_samples_split': 512} 0.5680847464819798\n",
      "{'n_estimators': 10, 'max_depth': 7, 'min_samples_split': 256} 0.5670255107788329\n",
      "{'n_estimators': 10, 'max_depth': 7, 'min_samples_split': 512} 0.5724060304780464\n",
      "{'n_estimators': 15, 'max_depth': 5, 'min_samples_split': 256} 0.5692073209929452\n",
      "{'n_estimators': 15, 'max_depth': 5, 'min_samples_split': 512} 0.5716407241067258\n",
      "{'n_estimators': 15, 'max_depth': 6, 'min_samples_split': 256} 0.5706158790202794\n",
      "{'n_estimators': 15, 'max_depth': 6, 'min_samples_split': 512} 0.5699305861415821\n",
      "{'n_estimators': 15, 'max_depth': 7, 'min_samples_split': 256} 0.5699417404975209\n",
      "{'n_estimators': 15, 'max_depth': 7, 'min_samples_split': 512} 0.5745226991354744\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# 탐색 대상 매개변수셋을 구성합니다.\n",
    "# itertools.product를 이용하면, 교차하는 경우를 쉽게 구성할 수 있습니다.\n",
    "params = [\n",
    "    {\n",
    "        'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': min_samples_split\n",
    "    }\n",
    "    for n_estimators, max_depth, min_samples_split in product([5, 10, 15], [5, 6, 7], [256, 512])\n",
    "]\n",
    "X_gscv = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "scores = list()\n",
    "for param in params:\n",
    "    clf_rf = RandomForestClassifier(**param, random_state=123)\n",
    "    # cross_val_score를 이용해 겹외셋에 대한 성능을 가져 옵니다. \n",
    "    scores.append(\n",
    "        np.mean(cross_val_score(clf_rf, df_prob3_train[X_gscv], df_prob3_train['failure'], \n",
    "                    cv=StratifiedKFold(5, random_state=123, shuffle=True), scoring='roc_auc'))\n",
    "    )\n",
    "    print(param, scores[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b3fd94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 15, 'max_depth': 7, 'min_samples_split': 512},\n",
       " 0.5745226991354744)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param = params[np.argmax(scores)]\n",
    "best_param, np.max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3711f314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'max_depth': 5, 'min_samples_split': 256} 0.5547115468443294\n",
      "{'n_estimators': 5, 'max_depth': 5, 'min_samples_split': 512} 0.5617150416141751\n",
      "{'n_estimators': 5, 'max_depth': 6, 'min_samples_split': 256} 0.5568999583940097\n",
      "{'n_estimators': 5, 'max_depth': 6, 'min_samples_split': 512} 0.5623239919998733\n",
      "{'n_estimators': 5, 'max_depth': 7, 'min_samples_split': 256} 0.5567633668997499\n",
      "{'n_estimators': 5, 'max_depth': 7, 'min_samples_split': 512} 0.5642015275666604\n",
      "{'n_estimators': 10, 'max_depth': 5, 'min_samples_split': 256} 0.5654552370913933\n",
      "{'n_estimators': 10, 'max_depth': 5, 'min_samples_split': 512} 0.5707474621000601\n",
      "{'n_estimators': 10, 'max_depth': 6, 'min_samples_split': 256} 0.5681316681217556\n",
      "{'n_estimators': 10, 'max_depth': 6, 'min_samples_split': 512} 0.5680847464819798\n",
      "{'n_estimators': 10, 'max_depth': 7, 'min_samples_split': 256} 0.5670255107788329\n",
      "{'n_estimators': 10, 'max_depth': 7, 'min_samples_split': 512} 0.5724060304780464\n",
      "{'n_estimators': 15, 'max_depth': 5, 'min_samples_split': 256} 0.5692073209929452\n",
      "{'n_estimators': 15, 'max_depth': 5, 'min_samples_split': 512} 0.5716407241067258\n",
      "{'n_estimators': 15, 'max_depth': 6, 'min_samples_split': 256} 0.5706158790202794\n",
      "{'n_estimators': 15, 'max_depth': 6, 'min_samples_split': 512} 0.5699305861415821\n",
      "{'n_estimators': 15, 'max_depth': 7, 'min_samples_split': 256} 0.5699417404975209\n",
      "{'n_estimators': 15, 'max_depth': 7, 'min_samples_split': 512} 0.5745226991354744\n"
     ]
    }
   ],
   "source": [
    "# 방법 3: 반복문 + 직접 교차 검증\n",
    "from itertools import product\n",
    "from sklearn.metrics import roc_auc_score\n",
    "params = [\n",
    "    {\n",
    "        'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': min_samples_split\n",
    "    }\n",
    "    for n_estimators, max_depth, min_samples_split in product([5, 10, 15], [5, 6, 7], [256, 512])\n",
    "]\n",
    "scores = []\n",
    "cv = StratifiedKFold(5, random_state=123, shuffle=True)\n",
    "for param in params:\n",
    "    clf_rf = RandomForestClassifier(**param, random_state=123)\n",
    "    cv_scores = []\n",
    "    # 교차 검증을 직접해봅니다.\n",
    "    # train_idx, test_idx 위치기반 인덱스를 넘겨줍니다.\n",
    "    for train_idx, test_idx in cv.split(df_prob3_train[X_gscv], df_prob3_train['failure']):\n",
    "        # iloc으로 검증 학습셋을 가져와 학습을 시킵니다.\n",
    "        clf_rf.fit(\n",
    "            df_prob3_train.iloc[train_idx][X_gscv], \n",
    "            df_prob3_train.iloc[train_idx]['failure']\n",
    "        )\n",
    "        # iloc으로 검증 테스트셋을 가져와 성능을 측정합니다.\n",
    "        cv_scores.append(\n",
    "            roc_auc_score(\n",
    "                df_prob3_train.iloc[test_idx]['failure'],\n",
    "                clf_rf.predict_proba(df_prob3_train.iloc[test_idx][X_gscv])[:, 1],\n",
    "            )\n",
    "        )\n",
    "    scores.append(np.mean(cv_scores))\n",
    "    print(param, scores[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacc40ad",
   "metadata": {},
   "source": [
    "## 단계 5-2\n",
    "\n",
    "단계 5-1에서 구한 최적 하이퍼 파라미터로 설정한 랜덤포레스트 분류기(Random-Forest Classifier)를 사용하여 prob3_train 학습하고, \n",
    "\n",
    "prob3_test로 성능을 측정하여 이 값을 A라고 한다.\n",
    "\n",
    "입력 변수: loading, measurement_0 ~ 17, na_1, na_2 (순서에 유의)\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC (area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.ensemble.RandomForestClassifier, random_state=123 \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ebecc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6416568062149542, 0.5687712018291998)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1: 가장 좋은 설정으로 다시 학습하여, 값을 도출합니다.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "clf_rf = RandomForestClassifier(\n",
    "    **best_params,\n",
    "    random_state=123\n",
    ")\n",
    "X_rf = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "clf_rf.fit(df_prob3_train[X_rf], df_prob3_train['failure'])\n",
    "A = roc_auc_score(df_prob3_test['failure'], clf_rf.predict_proba(df_prob3_test[X_rf])[:, 1])\n",
    "(\n",
    "    roc_auc_score(df_prob3_train['failure'], clf_rf.predict_proba(df_prob3_train[X_rf])[:, 1]),\n",
    "    A\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7772a94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6416568062149542, 0.5687712018291998)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법 2\n",
    "# Step 5-1에서 나온 gscv.best_estimator_ 도 유효합니다.\n",
    "A = roc_auc_score(df_prob3_test['failure'], gscv.best_estimator_.predict_proba(df_prob3_test[X_rf])[:, 1])\n",
    "(\n",
    "    roc_auc_score(df_prob3_train['failure'], gscv.best_estimator_.predict_proba(df_prob3_train[X_rf])[:, 1]),\n",
    "    A\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044dd522",
   "metadata": {},
   "source": [
    "A값을 소수점 넷째 자리에서 반올림하여 3째 자리까지 출력하시오.\n",
    "\n",
    "**0.569**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a20fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
